{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cf5-oDPjwf8"
      },
      "source": [
        "# Unit 8: Proximal Policy Gradient (PPO) with PyTorch ü§ñ\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/thumbnail.png\" alt=\"Unit 8\"/>\n",
        "\n",
        "\n",
        "In this notebook, you'll learn to **code your PPO agent from scratch with PyTorch using CleanRL implementation as model**.\n",
        "\n",
        "To test its robustness, we're going to train it in:\n",
        "\n",
        "- [LunarLander-v2 üöÄ](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fl6Rxt0lc0O"
      },
      "source": [
        "‚¨áÔ∏è Here is an example of what you will achieve. ‚¨áÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DbKfCj5ilgqT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "3263953c-76c0-4dab-b5b6-71a54b274c87"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcOFdWpnlxNf"
      },
      "source": [
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the GitHub Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives of this notebook üèÜ\n",
        "\n",
        "At the end of the notebook, you will:\n",
        "\n",
        "- Be able to **code your PPO agent from scratch using PyTorch**.\n",
        "- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score üî•.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T6lIPYFghhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook is from the Deep Reinforcement Learning Course\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>\n",
        "\n",
        "In this free course, you will:\n",
        "\n",
        "- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n",
        "- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- ü§ñ Train **agents in unique environments**\n",
        "\n",
        "Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n",
        "\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"
      ],
      "metadata": {
        "id": "Wp-rD6Fuhq31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites üèóÔ∏è\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "üî≤ üìö Study [PPO by reading Unit 8](https://huggingface.co/deep-rl-course/unit8/introduction) ü§ó  "
      ],
      "metadata": {
        "id": "rasqqGQlhujA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To validate this hands-on for the [certification process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process), you need to push one model, we don't ask for a minimal result but we **advise you to try different hyperparameters settings to get better results**.\n",
        "\n",
        "If you don't find your model, **go to the bottom of the page and click on the refresh button**\n",
        "\n",
        "For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ],
      "metadata": {
        "id": "PUFfMGOih3CW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the GPU üí™\n",
        "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ],
      "metadata": {
        "id": "PU4FVzaoM6fC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ],
      "metadata": {
        "id": "KV0NyFdQM9ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a virtual display üîΩ\n",
        "\n",
        "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n",
        "\n",
        "Hence the following cell will install the librairies and create and run a virtual screen üñ•"
      ],
      "metadata": {
        "id": "bTpYcVZVMzUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.0"
      ],
      "metadata": {
        "id": "Fd731S8-NuJA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "2187f8f0-f319-4c09-fe8a-a554486f1abb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting setuptools==65.5.0\n",
            "  Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 65.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-65.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jV6wjQ7Be7p5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!apt install swig cmake\n",
        "!pip install pyglet==1.5\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "ww5PQH1gNLI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d8b273-437e-436e-ff65-c9a3bbd3a2d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7b24d0a71ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncIgfNf3mOtc"
      },
      "source": [
        "## Install dependencies üîΩ\n",
        "For this exercise, we use `gym==0.22`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym==0.22\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install huggingface_hub\n",
        "!pip install gym[box2d]==0.22"
      ],
      "metadata": {
        "id": "9xZQFTPcsKUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72367812-f746-45e7-bb3f-1e8abede1471"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.22\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.22) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708363 sha256=94800970b12d832e545e687f470b56fe5ee7b058d129d7f5f94822447f66a3ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/e8/e8/6dfbc92a1dcd76c1a5e2bb982750fd6b7e792239f46039e6b1\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.22.0\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (65.5.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Requirement already satisfied: gym[box2d]==0.22 in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.22) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.22) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.22) (0.0.8)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d]==0.22)\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d]==0.22)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2349115 sha256=403fa7d1ca873ed4961a0428e697c6a4ccc00c3b9c50e6969fc10a4ad1389d95\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDkUufewmq6v"
      },
      "source": [
        "## Let's code PPO from scratch with Costa Huang tutorial\n",
        "- For the core implementation of PPO we're going to use the excellent [Costa Huang](https://costa.sh/) tutorial.\n",
        "- In addition to the tutorial, to go deeper you can read the 37 core implementation details: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n",
        "\n",
        "üëâ The video tutorial: https://youtu.be/MEt6rrxH8W4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aNgEL1_uvhaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f30520cc-e59c-4acd-ae81-d4d0eb68ff69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f34ILn7AvTbt"
      },
      "source": [
        "- The best is to code first on the cell below, this way, if you kill the machine **you don't loose the implementation**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code here:\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from distutils.util import strtobool\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "8sd07DA5LxrL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_bE708C6mhE7"
      },
      "outputs": [],
      "source": [
        "def make_env(gym_id, seed, idx, capture_video, run_name):\n",
        "    def thunk():\n",
        "        env = gym.make(gym_id)\n",
        "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "        if capture_video:\n",
        "            if idx == 0:\n",
        "                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
        "        env.seed(seed)\n",
        "        env.action_space.seed(seed)\n",
        "        env.observation_space.seed(seed)\n",
        "        return env\n",
        "\n",
        "    return thunk\n",
        "\n",
        "\n",
        "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
        "    torch.nn.init.orthogonal_(layer.weight, std)\n",
        "    torch.nn.init.constant_(layer.bias, bias_const)\n",
        "    return layer\n",
        "\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, envs):\n",
        "        super(Agent, self).__init__()\n",
        "        self.critic = nn.Sequential(\n",
        "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 1), std=1.0),\n",
        "        )\n",
        "        self.actor = nn.Sequential(\n",
        "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, envs.single_action_space.n), std=0.01),\n",
        "        )\n",
        "\n",
        "    def get_value(self, x):\n",
        "        return self.critic(x)\n",
        "\n",
        "    def get_action_and_value(self, x, action=None):\n",
        "        logits = self.actor(x)\n",
        "        probs = Categorical(logits=logits)\n",
        "        if action is None:\n",
        "            action = probs.sample()\n",
        "        return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_args():\n",
        "    # fmt: off\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n",
        "        help=\"the name of this experiment\")\n",
        "    parser.add_argument(\"--gym-id\", type=str, default=\"CartPole-v1\",\n",
        "        help=\"the id of the gym environment\")\n",
        "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
        "        help=\"the learning rate of the optimizer\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=1,\n",
        "        help=\"seed of the experiment\")\n",
        "    parser.add_argument(\"--total-timesteps\", type=int, default=25000,\n",
        "        help=\"total timesteps of the experiments\")\n",
        "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
        "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, cuda will be enabled by default\")\n",
        "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
        "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"ppo-implementation-details\",\n",
        "        help=\"the wandb's project name\")\n",
        "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
        "        help=\"the entity (team) of wandb's project\")\n",
        "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n",
        "\n",
        "    # Algorithm specific arguments\n",
        "    parser.add_argument(\"--num-envs\", type=int, default=4,\n",
        "        help=\"the number of parallel game environments\")\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
        "        help=\"the number of steps to run in each environment per policy rollout\")\n",
        "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
        "    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Use GAE for advantage computation\")\n",
        "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
        "        help=\"the discount factor gamma\")\n",
        "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
        "        help=\"the lambda for the general advantage estimation\")\n",
        "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
        "        help=\"the number of mini-batches\")\n",
        "    parser.add_argument(\"--update-epochs\", type=int, default=4,\n",
        "        help=\"the K epochs to update the policy\")\n",
        "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles advantages normalization\")\n",
        "    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n",
        "        help=\"the surrogate clipping coefficient\")\n",
        "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
        "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
        "        help=\"coefficient of the entropy\")\n",
        "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
        "        help=\"coefficient of the value function\")\n",
        "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
        "        help=\"the maximum norm for the gradient clipping\")\n",
        "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
        "        help=\"the target KL divergence threshold\")\n",
        "    args = parser.parse_args()\n",
        "    args.batch_size = int(args.num_envs * args.num_steps)\n",
        "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
        "    # fmt: on\n",
        "    return args"
      ],
      "metadata": {
        "id": "n71xipkALO5I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = parse_args()\n",
        "run_name = f\"{args.gym_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "if args.track:\n",
        "    import wandb\n",
        "\n",
        "    wandb.init(\n",
        "        project=args.wandb_project_name,\n",
        "        entity=args.wandb_entity,\n",
        "        sync_tensorboard=True,\n",
        "        config=vars(args),\n",
        "        name=run_name,\n",
        "        monitor_gym=True,\n",
        "        save_code=True,\n",
        "    )\n",
        "writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "writer.add_text(\n",
        "    \"hyperparameters\",\n",
        "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        ")\n",
        "\n",
        "# TRY NOT TO MODIFY: seeding\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "\n",
        "# env setup\n",
        "envs = gym.vector.SyncVectorEnv(\n",
        "    [make_env(args.gym_id, args.seed + i, i, args.capture_video, run_name) for i in range(args.num_envs)]\n",
        ")\n",
        "assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
        "\n",
        "agent = Agent(envs).to(device)\n",
        "optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n",
        "\n",
        "# ALGO Logic: Storage setup\n",
        "obs = torch.zeros((args.num_steps, args.num_envs) + envs.single_observation_space.shape).to(device)\n",
        "actions = torch.zeros((args.num_steps, args.num_envs) + envs.single_action_space.shape).to(device)\n",
        "logprobs = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "rewards = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "dones = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "values = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "\n",
        "# TRY NOT TO MODIFY: start the game\n",
        "global_step = 0\n",
        "start_time = time.time()\n",
        "next_obs = torch.Tensor(envs.reset()).to(device)\n",
        "next_done = torch.zeros(args.num_envs).to(device)\n",
        "num_updates = args.total_timesteps // args.batch_size\n",
        "\n",
        "for update in range(1, num_updates + 1):\n",
        "    # Annealing the rate if instructed to do so.\n",
        "    if args.anneal_lr:\n",
        "        frac = 1.0 - (update - 1.0) / num_updates\n",
        "        lrnow = frac * args.learning_rate\n",
        "        optimizer.param_groups[0][\"lr\"] = lrnow\n",
        "\n",
        "    for step in range(0, args.num_steps):\n",
        "        global_step += 1 * args.num_envs\n",
        "        obs[step] = next_obs\n",
        "        dones[step] = next_done\n",
        "\n",
        "        # ALGO LOGIC: action logic\n",
        "        with torch.no_grad():\n",
        "            action, logprob, _, value = agent.get_action_and_value(next_obs)\n",
        "            values[step] = value.flatten()\n",
        "        actions[step] = action\n",
        "        logprobs[step] = logprob\n",
        "\n",
        "        # TRY NOT TO MODIFY: execute the game and log data.\n",
        "        next_obs, reward, done, info = envs.step(action.cpu().numpy())\n",
        "        rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
        "        next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n",
        "\n",
        "        for item in info:\n",
        "            if \"episode\" in item.keys():\n",
        "                print(f\"global_step={global_step}, episodic_return={item['episode']['r']}\")\n",
        "                writer.add_scalar(\"charts/episodic_return\", item[\"episode\"][\"r\"], global_step)\n",
        "                writer.add_scalar(\"charts/episodic_length\", item[\"episode\"][\"l\"], global_step)\n",
        "                break\n",
        "\n",
        "    # bootstrap value if not done\n",
        "    with torch.no_grad():\n",
        "        next_value = agent.get_value(next_obs).reshape(1, -1)\n",
        "        if args.gae:\n",
        "            advantages = torch.zeros_like(rewards).to(device)\n",
        "            lastgaelam = 0\n",
        "            for t in reversed(range(args.num_steps)):\n",
        "                if t == args.num_steps - 1:\n",
        "                    nextnonterminal = 1.0 - next_done\n",
        "                    nextvalues = next_value\n",
        "                else:\n",
        "                    nextnonterminal = 1.0 - dones[t + 1]\n",
        "                    nextvalues = values[t + 1]\n",
        "                delta = rewards[t] + args.gamma * nextvalues * nextnonterminal - values[t]\n",
        "                advantages[t] = lastgaelam = delta + args.gamma * args.gae_lambda * nextnonterminal * lastgaelam\n",
        "            returns = advantages + values\n",
        "        else:\n",
        "            returns = torch.zeros_like(rewards).to(device)\n",
        "            for t in reversed(range(args.num_steps)):\n",
        "                if t == args.num_steps - 1:\n",
        "                    nextnonterminal = 1.0 - next_done\n",
        "                    next_return = next_value\n",
        "                else:\n",
        "                    nextnonterminal = 1.0 - dones[t + 1]\n",
        "                    next_return = returns[t + 1]\n",
        "                returns[t] = rewards[t] + args.gamma * nextnonterminal * next_return\n",
        "            advantages = returns - values\n",
        "\n",
        "    # flatten the batch\n",
        "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
        "    b_logprobs = logprobs.reshape(-1)\n",
        "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
        "    b_advantages = advantages.reshape(-1)\n",
        "    b_returns = returns.reshape(-1)\n",
        "    b_values = values.reshape(-1)\n",
        "\n",
        "    # Optimizing the policy and value network\n",
        "    b_inds = np.arange(args.batch_size)\n",
        "    clipfracs = []\n",
        "    for epoch in range(args.update_epochs):\n",
        "        np.random.shuffle(b_inds)\n",
        "        for start in range(0, args.batch_size, args.minibatch_size):\n",
        "            end = start + args.minibatch_size\n",
        "            mb_inds = b_inds[start:end]\n",
        "\n",
        "            _, newlogprob, entropy, newvalue = agent.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n",
        "            logratio = newlogprob - b_logprobs[mb_inds]\n",
        "            ratio = logratio.exp()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
        "                old_approx_kl = (-logratio).mean()\n",
        "                approx_kl = ((ratio - 1) - logratio).mean()\n",
        "                clipfracs += [((ratio - 1.0).abs() > args.clip_coef).float().mean().item()]\n",
        "\n",
        "            mb_advantages = b_advantages[mb_inds]\n",
        "            if args.norm_adv:\n",
        "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
        "\n",
        "            # Policy loss\n",
        "            pg_loss1 = -mb_advantages * ratio\n",
        "            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - args.clip_coef, 1 + args.clip_coef)\n",
        "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
        "\n",
        "            # Value loss\n",
        "            newvalue = newvalue.view(-1)\n",
        "            if args.clip_vloss:\n",
        "                v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n",
        "                v_clipped = b_values[mb_inds] + torch.clamp(\n",
        "                    newvalue - b_values[mb_inds],\n",
        "                    -args.clip_coef,\n",
        "                    args.clip_coef,\n",
        "                )\n",
        "                v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
        "                v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
        "                v_loss = 0.5 * v_loss_max.mean()\n",
        "            else:\n",
        "                v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n",
        "\n",
        "            entropy_loss = entropy.mean()\n",
        "            loss = pg_loss - args.ent_coef * entropy_loss + v_loss * args.vf_coef\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(agent.parameters(), args.max_grad_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "        if args.target_kl is not None:\n",
        "            if approx_kl > args.target_kl:\n",
        "                break\n",
        "\n",
        "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
        "    var_y = np.var(y_true)\n",
        "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
        "\n",
        "    # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
        "    writer.add_scalar(\"charts/learning_rate\", optimizer.param_groups[0][\"lr\"], global_step)\n",
        "    writer.add_scalar(\"losses/value_loss\", v_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/policy_loss\", pg_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/entropy\", entropy_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/old_approx_kl\", old_approx_kl.item(), global_step)\n",
        "    writer.add_scalar(\"losses/approx_kl\", approx_kl.item(), global_step)\n",
        "    writer.add_scalar(\"losses/clipfrac\", np.mean(clipfracs), global_step)\n",
        "    writer.add_scalar(\"losses/explained_variance\", explained_var, global_step)\n",
        "    print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
        "    writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "envs.close()\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "KPd5MKAILdwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk-a9CmNuS2W"
      },
      "source": [
        "## Add the Hugging Face Integration ü§ó\n",
        "- In order to push our model to the Hub, we need to define a function `package_to_hub`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPi1Nme-oGWd"
      },
      "source": [
        "- Add dependencies we need to push our model to the Hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ppo.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkro2ZmaMtMj",
        "outputId": "3e237a81-65c0-4f17-f545-791a3b5a3aed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2024-02-07 06:15:36.434721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-07 06:15:36.434791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-07 06:15:36.436474: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-07 06:15:36.446233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-07 06:15:40.697146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "global_step=44, episodic_return=11.0\n",
            "global_step=48, episodic_return=12.0\n",
            "global_step=56, episodic_return=14.0\n",
            "global_step=68, episodic_return=17.0\n",
            "global_step=136, episodic_return=23.0\n",
            "global_step=160, episodic_return=28.0\n",
            "global_step=172, episodic_return=9.0\n",
            "global_step=196, episodic_return=32.0\n",
            "global_step=248, episodic_return=13.0\n",
            "global_step=252, episodic_return=49.0\n",
            "global_step=328, episodic_return=19.0\n",
            "global_step=344, episodic_return=24.0\n",
            "global_step=384, episodic_return=53.0\n",
            "global_step=396, episodic_return=13.0\n",
            "global_step=412, episodic_return=17.0\n",
            "global_step=428, episodic_return=25.0\n",
            "global_step=456, episodic_return=18.0\n",
            "global_step=492, episodic_return=20.0\n",
            "global_step=504, episodic_return=12.0\n",
            "SPS: 884\n",
            "global_step=524, episodic_return=32.0\n",
            "global_step=576, episodic_return=21.0\n",
            "global_step=600, episodic_return=19.0\n",
            "global_step=668, episodic_return=60.0\n",
            "global_step=680, episodic_return=44.0\n",
            "global_step=708, episodic_return=33.0\n",
            "global_step=728, episodic_return=15.0\n",
            "global_step=732, episodic_return=13.0\n",
            "global_step=780, episodic_return=13.0\n",
            "global_step=784, episodic_return=46.0\n",
            "global_step=792, episodic_return=15.0\n",
            "global_step=864, episodic_return=18.0\n",
            "global_step=880, episodic_return=43.0\n",
            "global_step=916, episodic_return=13.0\n",
            "global_step=924, episodic_return=36.0\n",
            "global_step=936, episodic_return=14.0\n",
            "global_step=1000, episodic_return=19.0\n",
            "SPS: 1016\n",
            "global_step=1040, episodic_return=31.0\n",
            "global_step=1056, episodic_return=14.0\n",
            "global_step=1072, episodic_return=48.0\n",
            "global_step=1088, episodic_return=38.0\n",
            "global_step=1128, episodic_return=18.0\n",
            "global_step=1156, episodic_return=17.0\n",
            "global_step=1180, episodic_return=27.0\n",
            "global_step=1192, episodic_return=38.0\n",
            "global_step=1236, episodic_return=20.0\n",
            "global_step=1256, episodic_return=16.0\n",
            "global_step=1276, episodic_return=37.0\n",
            "global_step=1296, episodic_return=15.0\n",
            "global_step=1316, episodic_return=34.0\n",
            "global_step=1356, episodic_return=20.0\n",
            "global_step=1380, episodic_return=16.0\n",
            "global_step=1440, episodic_return=21.0\n",
            "global_step=1444, episodic_return=47.0\n",
            "global_step=1456, episodic_return=19.0\n",
            "global_step=1480, episodic_return=31.0\n",
            "global_step=1500, episodic_return=11.0\n",
            "global_step=1504, episodic_return=16.0\n",
            "SPS: 1095\n",
            "global_step=1564, episodic_return=21.0\n",
            "global_step=1588, episodic_return=22.0\n",
            "global_step=1608, episodic_return=11.0\n",
            "global_step=1616, episodic_return=28.0\n",
            "global_step=1672, episodic_return=21.0\n",
            "global_step=1756, episodic_return=37.0\n",
            "global_step=1800, episodic_return=74.0\n",
            "global_step=1816, episodic_return=36.0\n",
            "global_step=1824, episodic_return=52.0\n",
            "global_step=1852, episodic_return=13.0\n",
            "global_step=1884, episodic_return=32.0\n",
            "global_step=1892, episodic_return=17.0\n",
            "global_step=1924, episodic_return=27.0\n",
            "global_step=1948, episodic_return=16.0\n",
            "global_step=1980, episodic_return=14.0\n",
            "global_step=2020, episodic_return=18.0\n",
            "global_step=2036, episodic_return=14.0\n",
            "global_step=2048, episodic_return=39.0\n",
            "SPS: 1015\n",
            "global_step=2060, episodic_return=10.0\n",
            "global_step=2072, episodic_return=55.0\n",
            "global_step=2100, episodic_return=16.0\n",
            "global_step=2116, episodic_return=14.0\n",
            "global_step=2148, episodic_return=19.0\n",
            "global_step=2152, episodic_return=26.0\n",
            "global_step=2184, episodic_return=21.0\n",
            "global_step=2228, episodic_return=28.0\n",
            "global_step=2268, episodic_return=21.0\n",
            "global_step=2280, episodic_return=33.0\n",
            "global_step=2296, episodic_return=17.0\n",
            "global_step=2304, episodic_return=19.0\n",
            "global_step=2328, episodic_return=12.0\n",
            "global_step=2380, episodic_return=19.0\n",
            "global_step=2424, episodic_return=39.0\n",
            "global_step=2440, episodic_return=28.0\n",
            "global_step=2480, episodic_return=14.0\n",
            "global_step=2508, episodic_return=17.0\n",
            "global_step=2544, episodic_return=41.0\n",
            "SPS: 969\n",
            "global_step=2576, episodic_return=17.0\n",
            "global_step=2596, episodic_return=29.0\n",
            "global_step=2608, episodic_return=16.0\n",
            "global_step=2656, episodic_return=15.0\n",
            "global_step=2672, episodic_return=24.0\n",
            "global_step=2688, episodic_return=98.0\n",
            "global_step=2724, episodic_return=29.0\n",
            "global_step=2728, episodic_return=18.0\n",
            "global_step=2800, episodic_return=28.0\n",
            "global_step=2920, episodic_return=48.0\n",
            "global_step=2924, episodic_return=63.0\n",
            "global_step=2932, episodic_return=33.0\n",
            "global_step=2936, episodic_return=53.0\n",
            "global_step=2976, episodic_return=13.0\n",
            "global_step=2980, episodic_return=12.0\n",
            "global_step=2984, episodic_return=12.0\n",
            "global_step=3036, episodic_return=13.0\n",
            "SPS: 995\n",
            "global_step=3088, episodic_return=28.0\n",
            "global_step=3112, episodic_return=33.0\n",
            "global_step=3128, episodic_return=52.0\n",
            "global_step=3144, episodic_return=14.0\n",
            "global_step=3216, episodic_return=26.0\n",
            "global_step=3260, episodic_return=56.0\n",
            "global_step=3308, episodic_return=41.0\n",
            "global_step=3332, episodic_return=51.0\n",
            "global_step=3336, episodic_return=30.0\n",
            "global_step=3340, episodic_return=20.0\n",
            "global_step=3400, episodic_return=23.0\n",
            "global_step=3428, episodic_return=22.0\n",
            "global_step=3488, episodic_return=22.0\n",
            "global_step=3492, episodic_return=40.0\n",
            "global_step=3532, episodic_return=26.0\n",
            "global_step=3540, episodic_return=51.0\n",
            "global_step=3548, episodic_return=14.0\n",
            "SPS: 966\n",
            "global_step=3592, episodic_return=15.0\n",
            "global_step=3660, episodic_return=43.0\n",
            "global_step=3708, episodic_return=29.0\n",
            "global_step=3732, episodic_return=46.0\n",
            "global_step=3756, episodic_return=54.0\n",
            "global_step=3792, episodic_return=21.0\n",
            "global_step=3864, episodic_return=18.0\n",
            "global_step=3884, episodic_return=32.0\n",
            "global_step=3940, episodic_return=52.0\n",
            "global_step=3996, episodic_return=14.0\n",
            "global_step=4008, episodic_return=36.0\n",
            "global_step=4020, episodic_return=90.0\n",
            "SPS: 917\n",
            "global_step=4152, episodic_return=33.0\n",
            "global_step=4160, episodic_return=41.0\n",
            "global_step=4212, episodic_return=51.0\n",
            "global_step=4244, episodic_return=21.0\n",
            "global_step=4272, episodic_return=30.0\n",
            "global_step=4284, episodic_return=18.0\n",
            "global_step=4400, episodic_return=39.0\n",
            "global_step=4420, episodic_return=134.0\n",
            "global_step=4536, episodic_return=63.0\n",
            "global_step=4580, episodic_return=77.0\n",
            "SPS: 840\n",
            "global_step=4732, episodic_return=78.0\n",
            "global_step=4752, episodic_return=43.0\n",
            "global_step=4760, episodic_return=56.0\n",
            "global_step=4804, episodic_return=101.0\n",
            "global_step=4868, episodic_return=34.0\n",
            "global_step=4896, episodic_return=36.0\n",
            "global_step=4968, episodic_return=25.0\n",
            "global_step=5036, episodic_return=35.0\n",
            "global_step=5040, episodic_return=70.0\n",
            "global_step=5064, episodic_return=24.0\n",
            "global_step=5100, episodic_return=16.0\n",
            "SPS: 783\n",
            "global_step=5128, episodic_return=81.0\n",
            "global_step=5136, episodic_return=24.0\n",
            "global_step=5144, episodic_return=20.0\n",
            "global_step=5208, episodic_return=20.0\n",
            "global_step=5220, episodic_return=19.0\n",
            "global_step=5292, episodic_return=48.0\n",
            "global_step=5304, episodic_return=21.0\n",
            "global_step=5328, episodic_return=48.0\n",
            "global_step=5376, episodic_return=42.0\n",
            "global_step=5392, episodic_return=25.0\n",
            "global_step=5472, episodic_return=20.0\n",
            "global_step=5480, episodic_return=38.0\n",
            "global_step=5540, episodic_return=59.0\n",
            "global_step=5572, episodic_return=25.0\n",
            "SPS: 775\n",
            "global_step=5728, episodic_return=62.0\n",
            "global_step=5732, episodic_return=40.0\n",
            "global_step=5760, episodic_return=96.0\n",
            "global_step=5772, episodic_return=58.0\n",
            "global_step=5860, episodic_return=32.0\n",
            "global_step=5948, episodic_return=44.0\n",
            "global_step=5960, episodic_return=50.0\n",
            "global_step=6048, episodic_return=80.0\n",
            "global_step=6084, episodic_return=56.0\n",
            "global_step=6108, episodic_return=37.0\n",
            "SPS: 792\n",
            "global_step=6224, episodic_return=44.0\n",
            "global_step=6252, episodic_return=42.0\n",
            "global_step=6260, episodic_return=38.0\n",
            "global_step=6276, episodic_return=82.0\n",
            "global_step=6464, episodic_return=51.0\n",
            "global_step=6472, episodic_return=55.0\n",
            "global_step=6520, episodic_return=61.0\n",
            "global_step=6536, episodic_return=78.0\n",
            "global_step=6576, episodic_return=28.0\n",
            "global_step=6592, episodic_return=30.0\n",
            "SPS: 836\n",
            "global_step=6668, episodic_return=37.0\n",
            "global_step=6748, episodic_return=20.0\n",
            "global_step=6828, episodic_return=73.0\n",
            "global_step=6832, episodic_return=64.0\n",
            "global_step=6852, episodic_return=26.0\n",
            "global_step=6904, episodic_return=19.0\n",
            "global_step=6936, episodic_return=26.0\n",
            "global_step=7004, episodic_return=103.0\n",
            "global_step=7080, episodic_return=36.0\n",
            "global_step=7096, episodic_return=23.0\n",
            "global_step=7104, episodic_return=50.0\n",
            "global_step=7112, episodic_return=65.0\n",
            "SPS: 876\n",
            "global_step=7236, episodic_return=33.0\n",
            "global_step=7292, episodic_return=53.0\n",
            "global_step=7372, episodic_return=20.0\n",
            "global_step=7384, episodic_return=37.0\n",
            "global_step=7396, episodic_return=75.0\n",
            "global_step=7492, episodic_return=27.0\n",
            "global_step=7540, episodic_return=42.0\n",
            "global_step=7588, episodic_return=119.0\n",
            "global_step=7644, episodic_return=14.0\n",
            "global_step=7676, episodic_return=46.0\n",
            "global_step=7680, episodic_return=35.0\n",
            "SPS: 917\n",
            "global_step=7792, episodic_return=37.0\n",
            "global_step=7892, episodic_return=124.0\n",
            "global_step=7968, episodic_return=73.0\n",
            "global_step=7984, episodic_return=76.0\n",
            "global_step=8036, episodic_return=61.0\n",
            "global_step=8048, episodic_return=39.0\n",
            "global_step=8072, episodic_return=22.0\n",
            "global_step=8124, episodic_return=19.0\n",
            "global_step=8192, episodic_return=17.0\n",
            "SPS: 952\n",
            "global_step=8200, episodic_return=41.0\n",
            "global_step=8212, episodic_return=35.0\n",
            "global_step=8220, episodic_return=63.0\n",
            "global_step=8264, episodic_return=18.0\n",
            "global_step=8412, episodic_return=48.0\n",
            "global_step=8440, episodic_return=57.0\n",
            "global_step=8480, episodic_return=54.0\n",
            "global_step=8592, episodic_return=98.0\n",
            "global_step=8616, episodic_return=51.0\n",
            "global_step=8636, episodic_return=39.0\n",
            "global_step=8648, episodic_return=52.0\n",
            "SPS: 990\n",
            "global_step=8756, episodic_return=27.0\n",
            "global_step=8864, episodic_return=62.0\n",
            "global_step=8876, episodic_return=30.0\n",
            "global_step=8952, episodic_return=90.0\n",
            "global_step=9068, episodic_return=51.0\n",
            "global_step=9164, episodic_return=132.0\n",
            "SPS: 1027\n",
            "global_step=9344, episodic_return=117.0\n",
            "global_step=9376, episodic_return=77.0\n",
            "global_step=9532, episodic_return=92.0\n",
            "global_step=9556, episodic_return=151.0\n",
            "global_step=9592, episodic_return=54.0\n",
            "SPS: 1060\n",
            "global_step=9744, episodic_return=53.0\n",
            "global_step=9756, episodic_return=103.0\n",
            "global_step=9784, episodic_return=48.0\n",
            "global_step=9848, episodic_return=73.0\n",
            "global_step=9956, episodic_return=43.0\n",
            "global_step=9996, episodic_return=60.0\n",
            "global_step=10052, episodic_return=24.0\n",
            "global_step=10096, episodic_return=25.0\n",
            "global_step=10164, episodic_return=105.0\n",
            "global_step=10172, episodic_return=30.0\n",
            "SPS: 1090\n",
            "global_step=10328, episodic_return=41.0\n",
            "global_step=10356, episodic_return=46.0\n",
            "global_step=10508, episodic_return=45.0\n",
            "SPS: 1122\n",
            "global_step=10800, episodic_return=176.0\n",
            "global_step=10888, episodic_return=95.0\n",
            "global_step=11008, episodic_return=228.0\n",
            "global_step=11084, episodic_return=71.0\n",
            "global_step=11240, episodic_return=88.0\n",
            "SPS: 1152\n",
            "global_step=11276, episodic_return=230.0\n",
            "global_step=11316, episodic_return=58.0\n",
            "global_step=11388, episodic_return=37.0\n",
            "global_step=11456, episodic_return=45.0\n",
            "global_step=11584, episodic_return=144.0\n",
            "global_step=11608, episodic_return=73.0\n",
            "global_step=11776, episodic_return=97.0\n",
            "SPS: 1180\n",
            "global_step=11836, episodic_return=57.0\n",
            "global_step=11928, episodic_return=86.0\n",
            "global_step=12044, episodic_return=52.0\n",
            "global_step=12100, episodic_return=81.0\n",
            "global_step=12108, episodic_return=163.0\n",
            "global_step=12228, episodic_return=75.0\n",
            "global_step=12236, episodic_return=34.0\n",
            "SPS: 1207\n",
            "global_step=12364, episodic_return=34.0\n",
            "global_step=12488, episodic_return=111.0\n",
            "global_step=12572, episodic_return=84.0\n",
            "global_step=12608, episodic_return=125.0\n",
            "global_step=12628, episodic_return=66.0\n",
            "global_step=12708, episodic_return=55.0\n",
            "SPS: 1230\n",
            "global_step=12848, episodic_return=35.0\n",
            "global_step=12880, episodic_return=77.0\n",
            "global_step=12924, episodic_return=79.0\n",
            "global_step=13128, episodic_return=51.0\n",
            "global_step=13200, episodic_return=88.0\n",
            "SPS: 1254\n",
            "global_step=13316, episodic_return=47.0\n",
            "global_step=13348, episodic_return=117.0\n",
            "global_step=13536, episodic_return=47.0\n",
            "global_step=13552, episodic_return=88.0\n",
            "global_step=13672, episodic_return=89.0\n",
            "global_step=13680, episodic_return=32.0\n",
            "global_step=13780, episodic_return=288.0\n",
            "global_step=13796, episodic_return=65.0\n",
            "SPS: 1278\n",
            "global_step=13908, episodic_return=57.0\n",
            "global_step=13928, episodic_return=64.0\n",
            "global_step=14144, episodic_return=91.0\n",
            "global_step=14300, episodic_return=98.0\n",
            "global_step=14308, episodic_return=128.0\n",
            "SPS: 1302\n",
            "global_step=14356, episodic_return=53.0\n",
            "global_step=14704, episodic_return=99.0\n",
            "global_step=14744, episodic_return=111.0\n",
            "SPS: 1324\n",
            "global_step=14952, episodic_return=149.0\n",
            "global_step=15036, episodic_return=277.0\n",
            "global_step=15244, episodic_return=125.0\n",
            "global_step=15256, episodic_return=76.0\n",
            "global_step=15268, episodic_return=141.0\n",
            "SPS: 1345\n",
            "global_step=15472, episodic_return=51.0\n",
            "global_step=15536, episodic_return=70.0\n",
            "global_step=15584, episodic_return=85.0\n",
            "global_step=15672, episodic_return=159.0\n",
            "global_step=15752, episodic_return=54.0\n",
            "SPS: 1365\n",
            "global_step=15888, episodic_return=104.0\n",
            "global_step=16016, episodic_return=108.0\n",
            "SPS: 1386\n",
            "global_step=16416, episodic_return=100.0\n",
            "global_step=16420, episodic_return=187.0\n",
            "global_step=16512, episodic_return=23.0\n",
            "global_step=16560, episodic_return=168.0\n",
            "global_step=16768, episodic_return=254.0\n",
            "global_step=16804, episodic_return=73.0\n",
            "SPS: 1404\n",
            "global_step=16956, episodic_return=38.0\n",
            "global_step=17008, episodic_return=148.0\n",
            "global_step=17200, episodic_return=61.0\n",
            "global_step=17240, episodic_return=118.0\n",
            "global_step=17248, episodic_return=60.0\n",
            "SPS: 1424\n",
            "global_step=17628, episodic_return=267.0\n",
            "global_step=17800, episodic_return=150.0\n",
            "global_step=17844, episodic_return=149.0\n",
            "SPS: 1440\n",
            "global_step=17960, episodic_return=29.0\n",
            "global_step=17964, episodic_return=181.0\n",
            "global_step=17988, episodic_return=90.0\n",
            "global_step=18084, episodic_return=71.0\n",
            "global_step=18112, episodic_return=37.0\n",
            "global_step=18180, episodic_return=17.0\n",
            "global_step=18192, episodic_return=27.0\n",
            "global_step=18244, episodic_return=64.0\n",
            "global_step=18372, episodic_return=48.0\n",
            "SPS: 1458\n",
            "global_step=18552, episodic_return=148.0\n",
            "global_step=18596, episodic_return=101.0\n",
            "global_step=18656, episodic_return=71.0\n",
            "global_step=18904, episodic_return=77.0\n",
            "SPS: 1474\n",
            "global_step=19052, episodic_return=202.0\n",
            "global_step=19108, episodic_return=139.0\n",
            "global_step=19196, episodic_return=135.0\n",
            "global_step=19340, episodic_return=109.0\n",
            "global_step=19372, episodic_return=66.0\n",
            "global_step=19452, episodic_return=20.0\n",
            "SPS: 1492\n",
            "global_step=19556, episodic_return=126.0\n",
            "global_step=19584, episodic_return=61.0\n",
            "global_step=19704, episodic_return=63.0\n",
            "SPS: 1507\n",
            "global_step=19996, episodic_return=110.0\n",
            "global_step=20052, episodic_return=214.0\n",
            "global_step=20308, episodic_return=151.0\n",
            "SPS: 1519\n",
            "global_step=20520, episodic_return=131.0\n",
            "global_step=20668, episodic_return=154.0\n",
            "global_step=20696, episodic_return=278.0\n",
            "global_step=20804, episodic_return=124.0\n",
            "global_step=20824, episodic_return=76.0\n",
            "SPS: 1532\n",
            "global_step=21012, episodic_return=79.0\n",
            "global_step=21040, episodic_return=59.0\n",
            "global_step=21140, episodic_return=79.0\n",
            "global_step=21188, episodic_return=44.0\n",
            "global_step=21392, episodic_return=51.0\n",
            "SPS: 1547\n",
            "global_step=21532, episodic_return=123.0\n",
            "global_step=21576, episodic_return=109.0\n",
            "global_step=21640, episodic_return=243.0\n",
            "global_step=21800, episodic_return=67.0\n",
            "global_step=21844, episodic_return=113.0\n",
            "SPS: 1563\n",
            "global_step=22060, episodic_return=121.0\n",
            "global_step=22080, episodic_return=70.0\n",
            "global_step=22092, episodic_return=62.0\n",
            "global_step=22216, episodic_return=34.0\n",
            "global_step=22424, episodic_return=196.0\n",
            "SPS: 1579\n",
            "global_step=22608, episodic_return=98.0\n",
            "global_step=22732, episodic_return=168.0\n",
            "global_step=22736, episodic_return=161.0\n",
            "SPS: 1593\n",
            "global_step=23048, episodic_return=110.0\n",
            "global_step=23160, episodic_return=106.0\n",
            "global_step=23196, episodic_return=116.0\n",
            "global_step=23320, episodic_return=224.0\n",
            "SPS: 1607\n",
            "global_step=23744, episodic_return=174.0\n",
            "global_step=23804, episodic_return=161.0\n",
            "global_step=23856, episodic_return=165.0\n",
            "global_step=23892, episodic_return=143.0\n",
            "SPS: 1621\n",
            "global_step=24136, episodic_return=83.0\n",
            "global_step=24260, episodic_return=92.0\n",
            "global_step=24336, episodic_return=50.0\n",
            "global_step=24544, episodic_return=200.0\n",
            "SPS: 1635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Sj8bz-AmoNVj"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, upload_folder\n",
        "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
        "\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import tempfile\n",
        "import json\n",
        "import shutil\n",
        "import imageio\n",
        "\n",
        "from wasabi import Printer\n",
        "msg = Printer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rDr8-lWn0zi"
      },
      "source": [
        "- Add new argument in `parse_args()` function to define the repo-id where we want to push the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHQiqQEFn0QH"
      },
      "outputs": [],
      "source": [
        "# Adding HuggingFace argument\n",
        "parser.add_argument(\"--repo-id\", type=str, default=\"ThomasSimonini/ppo-CartPole-v1\", help=\"id of the model repository from the Hugging Face Hub {username/repo_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blLZMiBAoUVT"
      },
      "source": [
        "- Next, we add the methods needed to push the model to the Hub\n",
        "\n",
        "- These methods will:\n",
        "  - `_evalutate_agent()`: evaluate the agent.\n",
        "  - `_generate_model_card()`: generate the model card of your agent.\n",
        "  - `_record_video()`: record a video of your agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WlLcz4L9odXs"
      },
      "outputs": [],
      "source": [
        "def package_to_hub(repo_id,\n",
        "                model,\n",
        "                hyperparameters,\n",
        "                eval_env,\n",
        "                video_fps=30,\n",
        "                commit_message=\"Push agent to the Hub\",\n",
        "                token= None,\n",
        "                logs=None\n",
        "                ):\n",
        "  \"\"\"\n",
        "  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
        "  This method does the complete pipeline:\n",
        "  - It evaluates the model\n",
        "  - It generates the model card\n",
        "  - It generates a replay video of the agent\n",
        "  - It pushes everything to the hub\n",
        "  :param repo_id: id of the model repository from the Hugging Face Hub\n",
        "  :param model: trained model\n",
        "  :param eval_env: environment used to evaluate the agent\n",
        "  :param fps: number of fps for rendering the video\n",
        "  :param commit_message: commit message\n",
        "  :param logs: directory on local machine of tensorboard logs you'd like to upload\n",
        "  \"\"\"\n",
        "  msg.info(\n",
        "        \"This function will save, evaluate, generate a video of your agent, \"\n",
        "        \"create a model card and push everything to the hub. \"\n",
        "        \"It might take up to 1min. \\n \"\n",
        "        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n",
        "    )\n",
        "  # Step 1: Clone or create the repo\n",
        "  repo_url = HfApi().create_repo(\n",
        "        repo_id=repo_id,\n",
        "        token=token,\n",
        "        private=False,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "\n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    tmpdirname = Path(tmpdirname)\n",
        "\n",
        "    # Step 2: Save the model\n",
        "    torch.save(model.state_dict(), tmpdirname / \"model.pt\")\n",
        "\n",
        "    # Step 3: Evaluate the model and build JSON\n",
        "    mean_reward, std_reward = _evaluate_agent(eval_env,\n",
        "                                           10,\n",
        "                                           model)\n",
        "\n",
        "    # First get datetime\n",
        "    eval_datetime = datetime.datetime.now()\n",
        "    eval_form_datetime = eval_datetime.isoformat()\n",
        "\n",
        "    evaluate_data = {\n",
        "        \"env_id\": hyperparameters.env_id,\n",
        "        \"mean_reward\": mean_reward,\n",
        "        \"std_reward\": std_reward,\n",
        "        \"n_evaluation_episodes\": 10,\n",
        "        \"eval_datetime\": eval_form_datetime,\n",
        "    }\n",
        "\n",
        "    # Write a JSON file\n",
        "    with open(tmpdirname / \"results.json\", \"w\") as outfile:\n",
        "      json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 4: Generate a video\n",
        "    video_path =  tmpdirname / \"replay.mp4\"\n",
        "    record_video(eval_env, model, video_path, video_fps)\n",
        "\n",
        "    # Step 5: Generate the model card\n",
        "    generated_model_card, metadata = _generate_model_card(\"PPO\", hyperparameters.env_id, mean_reward, std_reward, hyperparameters)\n",
        "    _save_model_card(tmpdirname, generated_model_card, metadata)\n",
        "\n",
        "    # Step 6: Add logs if needed\n",
        "    if logs:\n",
        "      _add_logdir(tmpdirname, Path(logs))\n",
        "\n",
        "    msg.info(f\"Pushing repo {repo_id} to the Hugging Face Hub\")\n",
        "\n",
        "    repo_url = upload_folder(\n",
        "            repo_id=repo_id,\n",
        "            folder_path=tmpdirname,\n",
        "            path_in_repo=\"\",\n",
        "            commit_message=commit_message,\n",
        "            token=token,\n",
        "        )\n",
        "\n",
        "    msg.info(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")\n",
        "  return repo_url\n",
        "\n",
        "\n",
        "def _evaluate_agent(env, n_eval_episodes, policy):\n",
        "  \"\"\"\n",
        "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
        "  :param env: The evaluation environment\n",
        "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
        "  :param policy: The agent\n",
        "  \"\"\"\n",
        "  episode_rewards = []\n",
        "  for episode in range(n_eval_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards_ep = 0\n",
        "\n",
        "    while done is False:\n",
        "      state = torch.Tensor(state).to(device)\n",
        "      action, _, _, _ = policy.get_action_and_value(state)\n",
        "      new_state, reward, done, info = env.step(action.cpu().numpy())\n",
        "      total_rewards_ep += reward\n",
        "      if done:\n",
        "        break\n",
        "      state = new_state\n",
        "    episode_rewards.append(total_rewards_ep)\n",
        "  mean_reward = np.mean(episode_rewards)\n",
        "  std_reward = np.std(episode_rewards)\n",
        "\n",
        "  return mean_reward, std_reward\n",
        "\n",
        "\n",
        "def record_video(env, policy, out_directory, fps=30):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset()\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    state = torch.Tensor(state).to(device)\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action, _, _, _  = policy.get_action_and_value(state)\n",
        "    state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n",
        "\n",
        "\n",
        "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
        "  \"\"\"\n",
        "  Generate the model card for the Hub\n",
        "  :param model_name: name of the model\n",
        "  :env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  :hyperparameters: training arguments\n",
        "  \"\"\"\n",
        "  # Step 1: Select the tags\n",
        "  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
        "\n",
        "  # Transform the hyperparams namespace to string\n",
        "  converted_dict = vars(hyperparameters)\n",
        "  converted_str = str(converted_dict)\n",
        "  converted_str = converted_str.split(\", \")\n",
        "  converted_str = '\\n'.join(converted_str)\n",
        "\n",
        "  # Step 2: Generate the model card\n",
        "  model_card = f\"\"\"\n",
        "  # PPO Agent Playing {env_id}\n",
        "\n",
        "  This is a trained model of a PPO agent playing {env_id}.\n",
        "\n",
        "  # Hyperparameters\n",
        "  ```python\n",
        "  {converted_str}\n",
        "  ```\n",
        "  \"\"\"\n",
        "  return model_card, metadata\n",
        "\n",
        "\n",
        "def generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
        "  \"\"\"\n",
        "  Define the tags for the model card\n",
        "  :param model_name: name of the model\n",
        "  :param env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  \"\"\"\n",
        "  metadata = {}\n",
        "  metadata[\"tags\"] = [\n",
        "        env_id,\n",
        "        \"ppo\",\n",
        "        \"deep-reinforcement-learning\",\n",
        "        \"reinforcement-learning\",\n",
        "        \"custom-implementation\",\n",
        "        \"deep-rl-course\"\n",
        "  ]\n",
        "\n",
        "  # Add metrics\n",
        "  eval = metadata_eval_result(\n",
        "      model_pretty_name=model_name,\n",
        "      task_pretty_name=\"reinforcement-learning\",\n",
        "      task_id=\"reinforcement-learning\",\n",
        "      metrics_pretty_name=\"mean_reward\",\n",
        "      metrics_id=\"mean_reward\",\n",
        "      metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "      dataset_pretty_name=env_id,\n",
        "      dataset_id=env_id,\n",
        "  )\n",
        "\n",
        "  # Merges both dictionaries\n",
        "  metadata = {**metadata, **eval}\n",
        "\n",
        "  return metadata\n",
        "\n",
        "\n",
        "def _save_model_card(local_path, generated_model_card, metadata):\n",
        "    \"\"\"Saves a model card for the repository.\n",
        "    :param local_path: repository directory\n",
        "    :param generated_model_card: model card generated by _generate_model_card()\n",
        "    :param metadata: metadata\n",
        "    \"\"\"\n",
        "    readme_path = local_path / \"README.md\"\n",
        "    readme = \"\"\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "            readme = f.read()\n",
        "    else:\n",
        "        readme = generated_model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    # Save our metrics to Readme metadata\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "\n",
        "def _add_logdir(local_path: Path, logdir: Path):\n",
        "  \"\"\"Adds a logdir to the repository.\n",
        "  :param local_path: repository directory\n",
        "  :param logdir: logdir directory\n",
        "  \"\"\"\n",
        "  if logdir.exists() and logdir.is_dir():\n",
        "    # Add the logdir to the repository under new dir called logs\n",
        "    repo_logdir = local_path / \"logs\"\n",
        "\n",
        "    # Delete current logs if they exist\n",
        "    if repo_logdir.exists():\n",
        "      shutil.rmtree(repo_logdir)\n",
        "\n",
        "    # Copy logdir into repo logdir\n",
        "    shutil.copytree(logdir, repo_logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqX8z8_rooD6"
      },
      "source": [
        "- Finally, we call this function at the end of the PPO training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8V1vNiTo2hL"
      },
      "outputs": [],
      "source": [
        "# Create the evaluation environment\n",
        "eval_env = gym.make(args.env_id)\n",
        "\n",
        "package_to_hub(repo_id = args.repo_id,\n",
        "                model = agent, # The model we want to save\n",
        "                hyperparameters = args,\n",
        "                eval_env = gym.make(args.env_id),\n",
        "                logs= f\"runs/{run_name}\",\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muCCzed4o5TC"
      },
      "source": [
        "- Here's what look the ppo.py final file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LviRdtXgo7kF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "ddcbd65b-273d-482d-9dcd-1446ab77ecb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-912af683d357>\u001b[0m in \u001b[0;36m<cell line: 383>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-912af683d357>\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n\u001b[0m\u001b[1;32m     34\u001b[0m         help=\"the name of this experiment\")\n\u001b[1;32m     35\u001b[0m     parser.add_argument(\"--seed\", type=int, default=1,\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ],
      "source": [
        "# docs and experiment results can be found at https://docs.cleanrl.dev/rl-algorithms/ppo/#ppopy\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from distutils.util import strtobool\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from huggingface_hub import HfApi, upload_folder\n",
        "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
        "\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import tempfile\n",
        "import json\n",
        "import shutil\n",
        "import imageio\n",
        "\n",
        "from wasabi import Printer\n",
        "msg = Printer()\n",
        "\n",
        "def parse_args():\n",
        "    # fmt: off\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n",
        "        help=\"the name of this experiment\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=1,\n",
        "        help=\"seed of the experiment\")\n",
        "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
        "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, cuda will be enabled by default\")\n",
        "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
        "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"cleanRL\",\n",
        "        help=\"the wandb's project name\")\n",
        "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
        "        help=\"the entity (team) of wandb's project\")\n",
        "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n",
        "\n",
        "    # Algorithm specific arguments\n",
        "    parser.add_argument(\"--env-id\", type=str, default=\"CartPole-v1\",\n",
        "        help=\"the id of the environment\")\n",
        "    parser.add_argument(\"--total-timesteps\", type=int, default=50000,\n",
        "        help=\"total timesteps of the experiments\")\n",
        "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
        "        help=\"the learning rate of the optimizer\")\n",
        "    parser.add_argument(\"--num-envs\", type=int, default=4,\n",
        "        help=\"the number of parallel game environments\")\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
        "        help=\"the number of steps to run in each environment per policy rollout\")\n",
        "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
        "    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Use GAE for advantage computation\")\n",
        "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
        "        help=\"the discount factor gamma\")\n",
        "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
        "        help=\"the lambda for the general advantage estimation\")\n",
        "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
        "        help=\"the number of mini-batches\")\n",
        "    parser.add_argument(\"--update-epochs\", type=int, default=4,\n",
        "        help=\"the K epochs to update the policy\")\n",
        "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles advantages normalization\")\n",
        "    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n",
        "        help=\"the surrogate clipping coefficient\")\n",
        "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
        "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
        "        help=\"coefficient of the entropy\")\n",
        "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
        "        help=\"coefficient of the value function\")\n",
        "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
        "        help=\"the maximum norm for the gradient clipping\")\n",
        "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
        "        help=\"the target KL divergence threshold\")\n",
        "\n",
        "    # Adding HuggingFace argument\n",
        "    parser.add_argument(\"--repo-id\", type=str, default=\"ThomasSimonini/ppo-CartPole-v1\", help=\"id of the model repository from the Hugging Face Hub {username/repo_name}\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    args.batch_size = int(args.num_envs * args.num_steps)\n",
        "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
        "    # fmt: on\n",
        "    return args\n",
        "\n",
        "def package_to_hub(repo_id,\n",
        "                model,\n",
        "                hyperparameters,\n",
        "                eval_env,\n",
        "                video_fps=30,\n",
        "                commit_message=\"Push agent to the Hub\",\n",
        "                token= None,\n",
        "                logs=None\n",
        "                ):\n",
        "  \"\"\"\n",
        "  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
        "  This method does the complete pipeline:\n",
        "  - It evaluates the model\n",
        "  - It generates the model card\n",
        "  - It generates a replay video of the agent\n",
        "  - It pushes everything to the hub\n",
        "  :param repo_id: id of the model repository from the Hugging Face Hub\n",
        "  :param model: trained model\n",
        "  :param eval_env: environment used to evaluate the agent\n",
        "  :param fps: number of fps for rendering the video\n",
        "  :param commit_message: commit message\n",
        "  :param logs: directory on local machine of tensorboard logs you'd like to upload\n",
        "  \"\"\"\n",
        "  msg.info(\n",
        "        \"This function will save, evaluate, generate a video of your agent, \"\n",
        "        \"create a model card and push everything to the hub. \"\n",
        "        \"It might take up to 1min. \\n \"\n",
        "        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n",
        "    )\n",
        "  # Step 1: Clone or create the repo\n",
        "  repo_url = HfApi().create_repo(\n",
        "        repo_id=repo_id,\n",
        "        token=token,\n",
        "        private=False,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "\n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    tmpdirname = Path(tmpdirname)\n",
        "\n",
        "    # Step 2: Save the model\n",
        "    torch.save(model.state_dict(), tmpdirname / \"model.pt\")\n",
        "\n",
        "    # Step 3: Evaluate the model and build JSON\n",
        "    mean_reward, std_reward = _evaluate_agent(eval_env,\n",
        "                                           10,\n",
        "                                           model)\n",
        "\n",
        "    # First get datetime\n",
        "    eval_datetime = datetime.datetime.now()\n",
        "    eval_form_datetime = eval_datetime.isoformat()\n",
        "\n",
        "    evaluate_data = {\n",
        "        \"env_id\": hyperparameters.env_id,\n",
        "        \"mean_reward\": mean_reward,\n",
        "        \"std_reward\": std_reward,\n",
        "        \"n_evaluation_episodes\": 10,\n",
        "        \"eval_datetime\": eval_form_datetime,\n",
        "    }\n",
        "\n",
        "    # Write a JSON file\n",
        "    with open(tmpdirname / \"results.json\", \"w\") as outfile:\n",
        "      json.dump(evaluate_data, outfile)\n",
        "\n",
        "    # Step 4: Generate a video\n",
        "    video_path =  tmpdirname / \"replay.mp4\"\n",
        "    record_video(eval_env, model, video_path, video_fps)\n",
        "\n",
        "    # Step 5: Generate the model card\n",
        "    generated_model_card, metadata = _generate_model_card(\"PPO\", hyperparameters.env_id, mean_reward, std_reward, hyperparameters)\n",
        "    _save_model_card(tmpdirname, generated_model_card, metadata)\n",
        "\n",
        "    # Step 6: Add logs if needed\n",
        "    if logs:\n",
        "      _add_logdir(tmpdirname, Path(logs))\n",
        "\n",
        "    msg.info(f\"Pushing repo {repo_id} to the Hugging Face Hub\")\n",
        "\n",
        "    repo_url = upload_folder(\n",
        "            repo_id=repo_id,\n",
        "            folder_path=tmpdirname,\n",
        "            path_in_repo=\"\",\n",
        "            commit_message=commit_message,\n",
        "            token=token,\n",
        "        )\n",
        "\n",
        "    msg.info(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")\n",
        "  return repo_url\n",
        "\n",
        "def _evaluate_agent(env, n_eval_episodes, policy):\n",
        "  \"\"\"\n",
        "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
        "  :param env: The evaluation environment\n",
        "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
        "  :param policy: The agent\n",
        "  \"\"\"\n",
        "  episode_rewards = []\n",
        "  for episode in range(n_eval_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards_ep = 0\n",
        "\n",
        "    while done is False:\n",
        "      state = torch.Tensor(state).to(device)\n",
        "      action, _, _, _ = policy.get_action_and_value(state)\n",
        "      new_state, reward, done, info = env.step(action.cpu().numpy())\n",
        "      total_rewards_ep += reward\n",
        "      if done:\n",
        "        break\n",
        "      state = new_state\n",
        "    episode_rewards.append(total_rewards_ep)\n",
        "  mean_reward = np.mean(episode_rewards)\n",
        "  std_reward = np.std(episode_rewards)\n",
        "\n",
        "  return mean_reward, std_reward\n",
        "\n",
        "\n",
        "def record_video(env, policy, out_directory, fps=30):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset()\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    state = torch.Tensor(state).to(device)\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action, _, _, _  = policy.get_action_and_value(state)\n",
        "    state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n",
        "\n",
        "\n",
        "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
        "  \"\"\"\n",
        "  Generate the model card for the Hub\n",
        "  :param model_name: name of the model\n",
        "  :env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  :hyperparameters: training arguments\n",
        "  \"\"\"\n",
        "  # Step 1: Select the tags\n",
        "  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
        "\n",
        "  # Transform the hyperparams namespace to string\n",
        "  converted_dict = vars(hyperparameters)\n",
        "  converted_str = str(converted_dict)\n",
        "  converted_str = converted_str.split(\", \")\n",
        "  converted_str = '\\n'.join(converted_str)\n",
        "\n",
        "  # Step 2: Generate the model card\n",
        "  model_card = f\"\"\"\n",
        "  # PPO Agent Playing {env_id}\n",
        "\n",
        "  This is a trained model of a PPO agent playing {env_id}.\n",
        "\n",
        "  # Hyperparameters\n",
        "  ```python\n",
        "  {converted_str}\n",
        "  ```\n",
        "  \"\"\"\n",
        "  return model_card, metadata\n",
        "\n",
        "def generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
        "  \"\"\"\n",
        "  Define the tags for the model card\n",
        "  :param model_name: name of the model\n",
        "  :param env_id: name of the environment\n",
        "  :mean_reward: mean reward of the agent\n",
        "  :std_reward: standard deviation of the mean reward of the agent\n",
        "  \"\"\"\n",
        "  metadata = {}\n",
        "  metadata[\"tags\"] = [\n",
        "        env_id,\n",
        "        \"ppo\",\n",
        "        \"deep-reinforcement-learning\",\n",
        "        \"reinforcement-learning\",\n",
        "        \"custom-implementation\",\n",
        "        \"deep-rl-course\"\n",
        "  ]\n",
        "\n",
        "  # Add metrics\n",
        "  eval = metadata_eval_result(\n",
        "      model_pretty_name=model_name,\n",
        "      task_pretty_name=\"reinforcement-learning\",\n",
        "      task_id=\"reinforcement-learning\",\n",
        "      metrics_pretty_name=\"mean_reward\",\n",
        "      metrics_id=\"mean_reward\",\n",
        "      metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
        "      dataset_pretty_name=env_id,\n",
        "      dataset_id=env_id,\n",
        "  )\n",
        "\n",
        "  # Merges both dictionaries\n",
        "  metadata = {**metadata, **eval}\n",
        "\n",
        "  return metadata\n",
        "\n",
        "def _save_model_card(local_path, generated_model_card, metadata):\n",
        "    \"\"\"Saves a model card for the repository.\n",
        "    :param local_path: repository directory\n",
        "    :param generated_model_card: model card generated by _generate_model_card()\n",
        "    :param metadata: metadata\n",
        "    \"\"\"\n",
        "    readme_path = local_path / \"README.md\"\n",
        "    readme = \"\"\n",
        "    if readme_path.exists():\n",
        "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
        "            readme = f.read()\n",
        "    else:\n",
        "        readme = generated_model_card\n",
        "\n",
        "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    # Save our metrics to Readme metadata\n",
        "    metadata_save(readme_path, metadata)\n",
        "\n",
        "def _add_logdir(local_path: Path, logdir: Path):\n",
        "  \"\"\"Adds a logdir to the repository.\n",
        "  :param local_path: repository directory\n",
        "  :param logdir: logdir directory\n",
        "  \"\"\"\n",
        "  if logdir.exists() and logdir.is_dir():\n",
        "    # Add the logdir to the repository under new dir called logs\n",
        "    repo_logdir = local_path / \"logs\"\n",
        "\n",
        "    # Delete current logs if they exist\n",
        "    if repo_logdir.exists():\n",
        "      shutil.rmtree(repo_logdir)\n",
        "\n",
        "    # Copy logdir into repo logdir\n",
        "    shutil.copytree(logdir, repo_logdir)\n",
        "\n",
        "def make_env(env_id, seed, idx, capture_video, run_name):\n",
        "    def thunk():\n",
        "        env = gym.make(env_id)\n",
        "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "        if capture_video:\n",
        "            if idx == 0:\n",
        "                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
        "        env.seed(seed)\n",
        "        env.action_space.seed(seed)\n",
        "        env.observation_space.seed(seed)\n",
        "        return env\n",
        "\n",
        "    return thunk\n",
        "\n",
        "\n",
        "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
        "    torch.nn.init.orthogonal_(layer.weight, std)\n",
        "    torch.nn.init.constant_(layer.bias, bias_const)\n",
        "    return layer\n",
        "\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, envs):\n",
        "        super().__init__()\n",
        "        self.critic = nn.Sequential(\n",
        "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 1), std=1.0),\n",
        "        )\n",
        "        self.actor = nn.Sequential(\n",
        "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, 64)),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(64, envs.single_action_space.n), std=0.01),\n",
        "        )\n",
        "\n",
        "    def get_value(self, x):\n",
        "        return self.critic(x)\n",
        "\n",
        "    def get_action_and_value(self, x, action=None):\n",
        "        logits = self.actor(x)\n",
        "        probs = Categorical(logits=logits)\n",
        "        if action is None:\n",
        "            action = probs.sample()\n",
        "        return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "    if args.track:\n",
        "        import wandb\n",
        "\n",
        "        wandb.init(\n",
        "            project=args.wandb_project_name,\n",
        "            entity=args.wandb_entity,\n",
        "            sync_tensorboard=True,\n",
        "            config=vars(args),\n",
        "            name=run_name,\n",
        "            monitor_gym=True,\n",
        "            save_code=True,\n",
        "        )\n",
        "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "    writer.add_text(\n",
        "        \"hyperparameters\",\n",
        "        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        "    )\n",
        "\n",
        "    # TRY NOT TO MODIFY: seeding\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "\n",
        "    # env setup\n",
        "    envs = gym.vector.SyncVectorEnv(\n",
        "        [make_env(args.env_id, args.seed + i, i, args.capture_video, run_name) for i in range(args.num_envs)]\n",
        "    )\n",
        "    assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
        "\n",
        "    agent = Agent(envs).to(device)\n",
        "    optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n",
        "\n",
        "    # ALGO Logic: Storage setup\n",
        "    obs = torch.zeros((args.num_steps, args.num_envs) + envs.single_observation_space.shape).to(device)\n",
        "    actions = torch.zeros((args.num_steps, args.num_envs) + envs.single_action_space.shape).to(device)\n",
        "    logprobs = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "    rewards = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "    dones = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "    values = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "\n",
        "    # TRY NOT TO MODIFY: start the game\n",
        "    global_step = 0\n",
        "    start_time = time.time()\n",
        "    next_obs = torch.Tensor(envs.reset()).to(device)\n",
        "    next_done = torch.zeros(args.num_envs).to(device)\n",
        "    num_updates = args.total_timesteps // args.batch_size\n",
        "\n",
        "    for update in range(1, num_updates + 1):\n",
        "        # Annealing the rate if instructed to do so.\n",
        "        if args.anneal_lr:\n",
        "            frac = 1.0 - (update - 1.0) / num_updates\n",
        "            lrnow = frac * args.learning_rate\n",
        "            optimizer.param_groups[0][\"lr\"] = lrnow\n",
        "\n",
        "        for step in range(0, args.num_steps):\n",
        "            global_step += 1 * args.num_envs\n",
        "            obs[step] = next_obs\n",
        "            dones[step] = next_done\n",
        "\n",
        "            # ALGO LOGIC: action logic\n",
        "            with torch.no_grad():\n",
        "                action, logprob, _, value = agent.get_action_and_value(next_obs)\n",
        "                values[step] = value.flatten()\n",
        "            actions[step] = action\n",
        "            logprobs[step] = logprob\n",
        "\n",
        "            # TRY NOT TO MODIFY: execute the game and log data.\n",
        "            next_obs, reward, done, info = envs.step(action.cpu().numpy())\n",
        "            rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
        "            next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n",
        "\n",
        "            for item in info:\n",
        "                if \"episode\" in item.keys():\n",
        "                    print(f\"global_step={global_step}, episodic_return={item['episode']['r']}\")\n",
        "                    writer.add_scalar(\"charts/episodic_return\", item[\"episode\"][\"r\"], global_step)\n",
        "                    writer.add_scalar(\"charts/episodic_length\", item[\"episode\"][\"l\"], global_step)\n",
        "                    break\n",
        "\n",
        "        # bootstrap value if not done\n",
        "        with torch.no_grad():\n",
        "            next_value = agent.get_value(next_obs).reshape(1, -1)\n",
        "            if args.gae:\n",
        "                advantages = torch.zeros_like(rewards).to(device)\n",
        "                lastgaelam = 0\n",
        "                for t in reversed(range(args.num_steps)):\n",
        "                    if t == args.num_steps - 1:\n",
        "                        nextnonterminal = 1.0 - next_done\n",
        "                        nextvalues = next_value\n",
        "                    else:\n",
        "                        nextnonterminal = 1.0 - dones[t + 1]\n",
        "                        nextvalues = values[t + 1]\n",
        "                    delta = rewards[t] + args.gamma * nextvalues * nextnonterminal - values[t]\n",
        "                    advantages[t] = lastgaelam = delta + args.gamma * args.gae_lambda * nextnonterminal * lastgaelam\n",
        "                returns = advantages + values\n",
        "            else:\n",
        "                returns = torch.zeros_like(rewards).to(device)\n",
        "                for t in reversed(range(args.num_steps)):\n",
        "                    if t == args.num_steps - 1:\n",
        "                        nextnonterminal = 1.0 - next_done\n",
        "                        next_return = next_value\n",
        "                    else:\n",
        "                        nextnonterminal = 1.0 - dones[t + 1]\n",
        "                        next_return = returns[t + 1]\n",
        "                    returns[t] = rewards[t] + args.gamma * nextnonterminal * next_return\n",
        "                advantages = returns - values\n",
        "\n",
        "        # flatten the batch\n",
        "        b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
        "        b_logprobs = logprobs.reshape(-1)\n",
        "        b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
        "        b_advantages = advantages.reshape(-1)\n",
        "        b_returns = returns.reshape(-1)\n",
        "        b_values = values.reshape(-1)\n",
        "\n",
        "        # Optimizing the policy and value network\n",
        "        b_inds = np.arange(args.batch_size)\n",
        "        clipfracs = []\n",
        "        for epoch in range(args.update_epochs):\n",
        "            np.random.shuffle(b_inds)\n",
        "            for start in range(0, args.batch_size, args.minibatch_size):\n",
        "                end = start + args.minibatch_size\n",
        "                mb_inds = b_inds[start:end]\n",
        "\n",
        "                _, newlogprob, entropy, newvalue = agent.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n",
        "                logratio = newlogprob - b_logprobs[mb_inds]\n",
        "                ratio = logratio.exp()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
        "                    old_approx_kl = (-logratio).mean()\n",
        "                    approx_kl = ((ratio - 1) - logratio).mean()\n",
        "                    clipfracs += [((ratio - 1.0).abs() > args.clip_coef).float().mean().item()]\n",
        "\n",
        "                mb_advantages = b_advantages[mb_inds]\n",
        "                if args.norm_adv:\n",
        "                    mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
        "\n",
        "                # Policy loss\n",
        "                pg_loss1 = -mb_advantages * ratio\n",
        "                pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - args.clip_coef, 1 + args.clip_coef)\n",
        "                pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
        "\n",
        "                # Value loss\n",
        "                newvalue = newvalue.view(-1)\n",
        "                if args.clip_vloss:\n",
        "                    v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n",
        "                    v_clipped = b_values[mb_inds] + torch.clamp(\n",
        "                        newvalue - b_values[mb_inds],\n",
        "                        -args.clip_coef,\n",
        "                        args.clip_coef,\n",
        "                    )\n",
        "                    v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
        "                    v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
        "                    v_loss = 0.5 * v_loss_max.mean()\n",
        "                else:\n",
        "                    v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n",
        "\n",
        "                entropy_loss = entropy.mean()\n",
        "                loss = pg_loss - args.ent_coef * entropy_loss + v_loss * args.vf_coef\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(agent.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "\n",
        "            if args.target_kl is not None:\n",
        "                if approx_kl > args.target_kl:\n",
        "                    break\n",
        "\n",
        "        y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
        "        var_y = np.var(y_true)\n",
        "        explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
        "\n",
        "        # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
        "        writer.add_scalar(\"charts/learning_rate\", optimizer.param_groups[0][\"lr\"], global_step)\n",
        "        writer.add_scalar(\"losses/value_loss\", v_loss.item(), global_step)\n",
        "        writer.add_scalar(\"losses/policy_loss\", pg_loss.item(), global_step)\n",
        "        writer.add_scalar(\"losses/entropy\", entropy_loss.item(), global_step)\n",
        "        writer.add_scalar(\"losses/old_approx_kl\", old_approx_kl.item(), global_step)\n",
        "        writer.add_scalar(\"losses/approx_kl\", approx_kl.item(), global_step)\n",
        "        writer.add_scalar(\"losses/clipfrac\", np.mean(clipfracs), global_step)\n",
        "        writer.add_scalar(\"losses/explained_variance\", explained_var, global_step)\n",
        "        print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
        "        writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "    envs.close()\n",
        "    writer.close()\n",
        "\n",
        "    # Create the evaluation environment\n",
        "    eval_env = gym.make(args.env_id)\n",
        "\n",
        "    package_to_hub(repo_id = args.repo_id,\n",
        "                model = agent, # The model we want to save\n",
        "                hyperparameters = args,\n",
        "                eval_env = gym.make(args.env_id),\n",
        "                logs= f\"runs/{run_name}\",\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JquRrWytA6eo"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n",
        "\n",
        "2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n",
        "\n",
        "- Copy the token\n",
        "- Run the cell below and paste the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GZiFBBlzxzxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b4e709804cf048b0b088bdbb7fead0f0",
            "1c880e1666c042efa66f5cd280eb68e5",
            "9121302ae89b4a3e9c96aaace43584ae",
            "19f1f4ec716e48d0ba90be344bd9901e",
            "04f7eb6115d54030be33b730264233b7",
            "dedbc9335df24866bdf5b665ca28b165",
            "0fb05dfdefd441c29d5de83e0969a91d",
            "2d2e6986aad34282a54ed12af5fd3e84",
            "9d6b83b242354fc4b76d1f3679cc5b7a",
            "cdeb17b979d247d8b3c2dff49be30769",
            "03af986d99c048ddb691ac28997a6003",
            "90c49d0396d34086b96649c52225a43a",
            "0d804a48db694573896456faff94a036",
            "afb08af88dea45039fb8b48643390a49",
            "b7ddf907e5a94f88952f085a7884afe2",
            "83da2a0e44044e04a7bba948bcecd90c",
            "3be1337be02745e5877d73c9120aafd0",
            "f1d03a3f67e44c90a47e9c4925b1e472",
            "4b813ba9a73e467ead59249938186c2c",
            "b9777fb0b2224a35a2791293d9293dd5",
            "0a20d63c4a594dc98a9e7eafb33e4684",
            "75464c1f38904a689a8a5911d3b04aa4",
            "480856c9c36844b98daa9e104a365167",
            "49332511a2be40d1870f043060140f54",
            "9b918083d683485096d27364d85869e1",
            "93d42b6f467d4546b9d2983e177e71cc",
            "c9b2d8424c824c39a7a6a1010065ccea",
            "71bd8b4e48b946d280f5a512c74b1e34",
            "3e503fc32cfb423581b6c730f76e7e50",
            "08342d23ffde4cc0b1d3159814bbb97a",
            "ca1abcc3e2dc4ef98d54838e25212f0a",
            "38eb98b2171449329dd75535e183e399"
          ]
        },
        "outputId": "a8fa258f-cea5-4d37-e175-c5d3a4fed821"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4e709804cf048b0b088bdbb7fead0f0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tsf2uv0g_4p"
      },
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqkGvk7pFQ6"
      },
      "source": [
        "## Let's start the training üî•\n",
        "- ‚ö†Ô∏è ‚ö†Ô∏è ‚ö†Ô∏è  Don't use **the same repo id with the one you used for the Unit 1**\n",
        "- Now that you've coded from scratch PPO and added the Hugging Face Integration, we're ready to start the training üî•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tmEArP8ug2l"
      },
      "source": [
        "- First, you need to copy all your code to a file you create called `ppo.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/step1.png\" alt=\"PPO\"/>"
      ],
      "metadata": {
        "id": "Sq0My0LOjPYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/step2.png\" alt=\"PPO\"/>"
      ],
      "metadata": {
        "id": "A8C-Q5ZyjUe3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrS80GmMu_j5"
      },
      "source": [
        "- Now we just need to run this python script using `python <name-of-python-script>.py` with the additional parameters we defined with `argparse`\n",
        "\n",
        "- You should modify more hyperparameters otherwise the training will not be super stable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ppo.py --env-id=\"LunarLander-v2\" --repo-id=\"ramsi-k/LunarLander-v2-fromscratch\" --total-timesteps=50000"
      ],
      "metadata": {
        "id": "KXLih6mKseBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26043b1f-6187-47f5-dd3f-6bf6531f44e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2024-02-07 09:37:22.600224: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-07 09:37:22.600338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-07 09:37:22.603315: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-07 09:37:24.586256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "global_step=392, episodic_return=-163.16757202148438\n",
            "global_step=400, episodic_return=-144.61959838867188\n",
            "global_step=440, episodic_return=-98.68854522705078\n",
            "global_step=488, episodic_return=-263.014892578125\n",
            "SPS: 1589\n",
            "global_step=740, episodic_return=-145.6043701171875\n",
            "global_step=796, episodic_return=-281.3707580566406\n",
            "global_step=828, episodic_return=-68.95193481445312\n",
            "global_step=972, episodic_return=-86.589599609375\n",
            "SPS: 1661\n",
            "global_step=1112, episodic_return=10.265060424804688\n",
            "global_step=1160, episodic_return=-433.3804626464844\n",
            "global_step=1256, episodic_return=-30.75696563720703\n",
            "global_step=1360, episodic_return=-53.94366455078125\n",
            "global_step=1424, episodic_return=-92.64549255371094\n",
            "global_step=1464, episodic_return=-211.3941650390625\n",
            "SPS: 1683\n",
            "global_step=1656, episodic_return=-112.95364379882812\n",
            "global_step=1668, episodic_return=-346.16302490234375\n",
            "global_step=1852, episodic_return=-97.59037017822266\n",
            "global_step=1868, episodic_return=-447.5853271484375\n",
            "SPS: 1672\n",
            "global_step=2136, episodic_return=-229.0791778564453\n",
            "global_step=2156, episodic_return=-341.640380859375\n",
            "global_step=2160, episodic_return=-92.48570251464844\n",
            "global_step=2200, episodic_return=-171.155029296875\n",
            "global_step=2412, episodic_return=-87.27450561523438\n",
            "global_step=2464, episodic_return=-68.10127258300781\n",
            "global_step=2468, episodic_return=-102.74312591552734\n",
            "SPS: 1682\n",
            "global_step=2616, episodic_return=-465.5767517089844\n",
            "global_step=2772, episodic_return=-104.65029907226562\n",
            "global_step=2788, episodic_return=-262.6619873046875\n",
            "global_step=2880, episodic_return=-402.93707275390625\n",
            "global_step=3020, episodic_return=-131.5436553955078\n",
            "global_step=3052, episodic_return=-324.85601806640625\n",
            "SPS: 1680\n",
            "global_step=3092, episodic_return=-201.8812713623047\n",
            "global_step=3236, episodic_return=-246.27931213378906\n",
            "global_step=3416, episodic_return=-144.29002380371094\n",
            "global_step=3496, episodic_return=-101.54747772216797\n",
            "global_step=3532, episodic_return=-458.7062072753906\n",
            "SPS: 1674\n",
            "global_step=3652, episodic_return=-206.569580078125\n",
            "global_step=3744, episodic_return=-392.58349609375\n",
            "global_step=3908, episodic_return=-110.5404052734375\n",
            "global_step=3944, episodic_return=-277.19915771484375\n",
            "global_step=3988, episodic_return=-145.3758087158203\n",
            "SPS: 1689\n",
            "global_step=4152, episodic_return=-44.360538482666016\n",
            "global_step=4248, episodic_return=-359.62603759765625\n",
            "global_step=4380, episodic_return=-132.70916748046875\n",
            "global_step=4452, episodic_return=-89.71644592285156\n",
            "SPS: 1696\n",
            "global_step=4636, episodic_return=-179.37255859375\n",
            "global_step=4728, episodic_return=-126.2931900024414\n",
            "global_step=4832, episodic_return=-128.15333557128906\n",
            "global_step=4932, episodic_return=-148.1731414794922\n",
            "global_step=4936, episodic_return=-179.2928466796875\n",
            "global_step=5060, episodic_return=-309.4835510253906\n",
            "SPS: 1701\n",
            "global_step=5172, episodic_return=-384.1321716308594\n",
            "global_step=5264, episodic_return=-164.84432983398438\n",
            "global_step=5316, episodic_return=-469.6771240234375\n",
            "global_step=5432, episodic_return=-149.1930694580078\n",
            "global_step=5512, episodic_return=-110.37626647949219\n",
            "SPS: 1698\n",
            "global_step=5664, episodic_return=-112.27738189697266\n",
            "global_step=5772, episodic_return=-204.7833251953125\n",
            "global_step=5784, episodic_return=-87.37052154541016\n",
            "global_step=6072, episodic_return=-330.84393310546875\n",
            "global_step=6144, episodic_return=-220.68014526367188\n",
            "SPS: 1694\n",
            "global_step=6208, episodic_return=-142.4869384765625\n",
            "global_step=6228, episodic_return=-98.45110321044922\n",
            "global_step=6464, episodic_return=-280.416259765625\n",
            "global_step=6480, episodic_return=-122.00413513183594\n",
            "global_step=6608, episodic_return=-168.13751220703125\n",
            "SPS: 1683\n",
            "global_step=6700, episodic_return=-283.08135986328125\n",
            "global_step=6748, episodic_return=-115.56787109375\n",
            "global_step=6996, episodic_return=-348.84375\n",
            "global_step=7068, episodic_return=-102.355224609375\n",
            "global_step=7156, episodic_return=-157.3196563720703\n",
            "SPS: 1628\n",
            "global_step=7200, episodic_return=-311.02783203125\n",
            "global_step=7452, episodic_return=-357.273681640625\n",
            "global_step=7524, episodic_return=-85.71331024169922\n",
            "global_step=7572, episodic_return=-323.191162109375\n",
            "SPS: 1599\n",
            "global_step=7692, episodic_return=-177.5238494873047\n",
            "global_step=7760, episodic_return=-95.74593353271484\n",
            "global_step=7892, episodic_return=-87.9767074584961\n",
            "global_step=8020, episodic_return=-110.24456787109375\n",
            "global_step=8068, episodic_return=-346.1581115722656\n",
            "global_step=8176, episodic_return=-190.3421630859375\n",
            "SPS: 1571\n",
            "global_step=8340, episodic_return=-105.80367279052734\n",
            "global_step=8388, episodic_return=-224.33621215820312\n",
            "global_step=8484, episodic_return=-179.01083374023438\n",
            "global_step=8640, episodic_return=-202.82791137695312\n",
            "SPS: 1531\n",
            "global_step=8884, episodic_return=-102.39881896972656\n",
            "global_step=8964, episodic_return=-43.45799255371094\n",
            "global_step=9004, episodic_return=4.400505065917969\n",
            "global_step=9076, episodic_return=-204.07168579101562\n",
            "SPS: 1503\n",
            "global_step=9256, episodic_return=-76.67822265625\n",
            "global_step=9308, episodic_return=-196.6208038330078\n",
            "global_step=9324, episodic_return=-108.84538269042969\n",
            "global_step=9384, episodic_return=-170.9572296142578\n",
            "global_step=9628, episodic_return=-173.1566162109375\n",
            "global_step=9640, episodic_return=-188.18182373046875\n",
            "global_step=9692, episodic_return=-307.398681640625\n",
            "global_step=9696, episodic_return=-196.46522521972656\n",
            "SPS: 1483\n",
            "global_step=9904, episodic_return=-149.94090270996094\n",
            "global_step=10008, episodic_return=-317.18756103515625\n",
            "global_step=10060, episodic_return=-113.81094360351562\n",
            "global_step=10064, episodic_return=-133.34722900390625\n",
            "global_step=10228, episodic_return=-111.36970520019531\n",
            "SPS: 1492\n",
            "global_step=10444, episodic_return=-192.37847900390625\n",
            "global_step=10500, episodic_return=-326.44952392578125\n",
            "global_step=10516, episodic_return=-184.44680786132812\n",
            "global_step=10692, episodic_return=-57.33518981933594\n",
            "global_step=10708, episodic_return=-114.21502685546875\n",
            "SPS: 1499\n",
            "global_step=10800, episodic_return=-151.06204223632812\n",
            "global_step=11028, episodic_return=-112.65054321289062\n",
            "global_step=11040, episodic_return=-124.16199493408203\n",
            "global_step=11104, episodic_return=-371.7974548339844\n",
            "global_step=11108, episodic_return=-117.04947662353516\n",
            "SPS: 1505\n",
            "global_step=11368, episodic_return=-466.0603942871094\n",
            "global_step=11436, episodic_return=-110.35459899902344\n",
            "global_step=11492, episodic_return=-326.8477783203125\n",
            "global_step=11500, episodic_return=-111.70780944824219\n",
            "SPS: 1511\n",
            "global_step=11888, episodic_return=-337.757568359375\n",
            "global_step=11904, episodic_return=-133.04718017578125\n",
            "global_step=11908, episodic_return=-122.72892761230469\n",
            "global_step=11932, episodic_return=-265.48895263671875\n",
            "global_step=12160, episodic_return=-120.60932159423828\n",
            "global_step=12244, episodic_return=-124.48968505859375\n",
            "SPS: 1517\n",
            "global_step=12332, episodic_return=-339.5765380859375\n",
            "global_step=12456, episodic_return=-90.8394546508789\n",
            "global_step=12480, episodic_return=-458.74151611328125\n",
            "global_step=12672, episodic_return=-151.33517456054688\n",
            "SPS: 1516\n",
            "global_step=12824, episodic_return=-149.931396484375\n",
            "global_step=12924, episodic_return=-77.47876739501953\n",
            "global_step=12968, episodic_return=-203.86166381835938\n",
            "global_step=13036, episodic_return=-100.13206481933594\n",
            "global_step=13280, episodic_return=-85.33428192138672\n",
            "global_step=13292, episodic_return=-258.9697265625\n",
            "SPS: 1522\n",
            "global_step=13468, episodic_return=-126.30072784423828\n",
            "global_step=13504, episodic_return=-170.57476806640625\n",
            "global_step=13676, episodic_return=-244.07339477539062\n",
            "SPS: 1527\n",
            "global_step=13864, episodic_return=-149.38345336914062\n",
            "global_step=13880, episodic_return=-56.10641860961914\n",
            "global_step=13908, episodic_return=-123.88201904296875\n",
            "global_step=14140, episodic_return=-77.34127807617188\n",
            "global_step=14160, episodic_return=-219.854736328125\n",
            "global_step=14200, episodic_return=-93.624755859375\n",
            "global_step=14332, episodic_return=-259.7945861816406\n",
            "SPS: 1532\n",
            "global_step=14480, episodic_return=-406.75592041015625\n",
            "global_step=14544, episodic_return=-116.38862609863281\n",
            "global_step=14732, episodic_return=-329.793701171875\n",
            "global_step=14744, episodic_return=-239.59059143066406\n",
            "global_step=14832, episodic_return=-113.65460968017578\n",
            "SPS: 1533\n",
            "global_step=15012, episodic_return=-203.25936889648438\n",
            "global_step=15188, episodic_return=-171.1969451904297\n",
            "global_step=15192, episodic_return=-148.99636840820312\n",
            "global_step=15200, episodic_return=-125.50170135498047\n",
            "SPS: 1529\n",
            "global_step=15484, episodic_return=-149.61752319335938\n",
            "global_step=15496, episodic_return=-105.4449234008789\n",
            "global_step=15560, episodic_return=-219.26771545410156\n",
            "global_step=15732, episodic_return=-182.30401611328125\n",
            "SPS: 1533\n",
            "global_step=15908, episodic_return=-348.87347412109375\n",
            "global_step=15996, episodic_return=-139.78773498535156\n",
            "global_step=16064, episodic_return=-321.0924072265625\n",
            "global_step=16072, episodic_return=-80.04632568359375\n",
            "global_step=16156, episodic_return=-92.28759002685547\n",
            "global_step=16280, episodic_return=-97.17207336425781\n",
            "SPS: 1536\n",
            "global_step=16476, episodic_return=-322.89532470703125\n",
            "global_step=16516, episodic_return=-215.8426971435547\n",
            "global_step=16596, episodic_return=-98.37547302246094\n",
            "global_step=16624, episodic_return=-124.51878356933594\n",
            "global_step=16784, episodic_return=-69.64332580566406\n",
            "SPS: 1541\n",
            "global_step=16964, episodic_return=-172.5413818359375\n",
            "global_step=17008, episodic_return=-208.95957946777344\n",
            "global_step=17068, episodic_return=-38.40357208251953\n",
            "global_step=17160, episodic_return=-121.75415802001953\n",
            "global_step=17300, episodic_return=-104.49445343017578\n",
            "global_step=17380, episodic_return=-130.55409240722656\n",
            "SPS: 1542\n",
            "global_step=17508, episodic_return=-177.70130920410156\n",
            "global_step=17544, episodic_return=-77.0133056640625\n",
            "global_step=17632, episodic_return=-61.746971130371094\n",
            "global_step=17740, episodic_return=-103.57728576660156\n",
            "global_step=17796, episodic_return=-44.203914642333984\n",
            "global_step=17820, episodic_return=-162.87603759765625\n",
            "SPS: 1538\n",
            "global_step=17956, episodic_return=-297.3549499511719\n",
            "global_step=18156, episodic_return=-198.92889404296875\n",
            "global_step=18216, episodic_return=-275.88946533203125\n",
            "global_step=18352, episodic_return=-201.32907104492188\n",
            "global_step=18396, episodic_return=-117.79402160644531\n",
            "SPS: 1541\n",
            "global_step=18540, episodic_return=-268.62286376953125\n",
            "global_step=18584, episodic_return=-310.3345947265625\n",
            "global_step=18700, episodic_return=-91.05075073242188\n",
            "global_step=18720, episodic_return=-122.62478637695312\n",
            "global_step=18868, episodic_return=-64.94325256347656\n",
            "global_step=18896, episodic_return=-223.8247528076172\n",
            "SPS: 1545\n",
            "global_step=19164, episodic_return=-341.1868591308594\n",
            "global_step=19208, episodic_return=-172.14755249023438\n",
            "global_step=19244, episodic_return=-272.39434814453125\n",
            "global_step=19324, episodic_return=-123.20220184326172\n",
            "SPS: 1548\n",
            "global_step=19576, episodic_return=-105.61227416992188\n",
            "global_step=19628, episodic_return=-154.50128173828125\n",
            "global_step=19716, episodic_return=-50.210472106933594\n",
            "global_step=19740, episodic_return=-165.08262634277344\n",
            "global_step=19828, episodic_return=-80.6243667602539\n",
            "global_step=19968, episodic_return=-174.86492919921875\n",
            "SPS: 1551\n",
            "global_step=20180, episodic_return=-4.6287841796875\n",
            "global_step=20200, episodic_return=-79.65318298339844\n",
            "global_step=20212, episodic_return=-141.39227294921875\n",
            "global_step=20356, episodic_return=-118.24268341064453\n",
            "SPS: 1554\n",
            "global_step=20484, episodic_return=-120.7742691040039\n",
            "global_step=20532, episodic_return=-122.39007568359375\n",
            "global_step=20744, episodic_return=-275.6248779296875\n",
            "global_step=20756, episodic_return=-46.52923583984375\n",
            "global_step=20832, episodic_return=-210.30340576171875\n",
            "global_step=20848, episodic_return=35.61767578125\n",
            "SPS: 1556\n",
            "global_step=21032, episodic_return=-16.536819458007812\n",
            "global_step=21192, episodic_return=-120.21033477783203\n",
            "global_step=21316, episodic_return=-177.4986572265625\n",
            "global_step=21368, episodic_return=-184.548828125\n",
            "global_step=21408, episodic_return=-227.79666137695312\n",
            "SPS: 1558\n",
            "global_step=21612, episodic_return=-134.0861053466797\n",
            "global_step=21720, episodic_return=-265.4031066894531\n",
            "global_step=21728, episodic_return=-110.7313003540039\n",
            "global_step=21812, episodic_return=-79.44882202148438\n",
            "SPS: 1560\n",
            "global_step=22036, episodic_return=-84.39175415039062\n",
            "global_step=22112, episodic_return=-130.1974639892578\n",
            "global_step=22120, episodic_return=-130.374755859375\n",
            "global_step=22124, episodic_return=-83.80028533935547\n",
            "global_step=22372, episodic_return=-95.45521545410156\n",
            "global_step=22408, episodic_return=-191.9951171875\n",
            "SPS: 1563\n",
            "global_step=22592, episodic_return=-148.71603393554688\n",
            "global_step=22608, episodic_return=-181.00692749023438\n",
            "global_step=22672, episodic_return=-70.61255645751953\n",
            "global_step=22884, episodic_return=-153.22154235839844\n",
            "global_step=22892, episodic_return=-111.9649887084961\n",
            "global_step=22916, episodic_return=-131.86424255371094\n",
            "global_step=22932, episodic_return=-69.57872772216797\n",
            "SPS: 1564\n",
            "global_step=23216, episodic_return=-57.41313171386719\n",
            "global_step=23288, episodic_return=-97.70430755615234\n",
            "global_step=23304, episodic_return=-297.33673095703125\n",
            "global_step=23440, episodic_return=-201.9632568359375\n",
            "global_step=23508, episodic_return=-82.6225814819336\n",
            "SPS: 1567\n",
            "global_step=23564, episodic_return=-170.49566650390625\n",
            "global_step=23680, episodic_return=-67.43647766113281\n",
            "global_step=23712, episodic_return=-277.557861328125\n",
            "global_step=23952, episodic_return=-76.79081726074219\n",
            "global_step=24004, episodic_return=-90.86695098876953\n",
            "global_step=24036, episodic_return=-141.8206787109375\n",
            "global_step=24048, episodic_return=-103.93163299560547\n",
            "SPS: 1571\n",
            "global_step=24336, episodic_return=-122.84754180908203\n",
            "global_step=24396, episodic_return=-108.31279754638672\n",
            "global_step=24496, episodic_return=-228.08937072753906\n",
            "global_step=24540, episodic_return=-196.0313720703125\n",
            "SPS: 1570\n",
            "global_step=24628, episodic_return=-54.05145263671875\n",
            "global_step=24760, episodic_return=-198.40237426757812\n",
            "global_step=24836, episodic_return=-82.03559875488281\n",
            "global_step=24912, episodic_return=-108.00300598144531\n",
            "global_step=24996, episodic_return=-178.01219177246094\n",
            "global_step=25052, episodic_return=-242.29888916015625\n",
            "SPS: 1573\n",
            "global_step=25216, episodic_return=-163.76068115234375\n",
            "global_step=25348, episodic_return=-195.11703491210938\n",
            "global_step=25368, episodic_return=-124.87153625488281\n",
            "global_step=25496, episodic_return=-108.48712921142578\n",
            "SPS: 1575\n",
            "global_step=25680, episodic_return=-250.38710021972656\n",
            "global_step=25752, episodic_return=-236.96812438964844\n",
            "global_step=25880, episodic_return=-133.99005126953125\n",
            "global_step=26012, episodic_return=-254.631103515625\n",
            "global_step=26036, episodic_return=-56.644309997558594\n",
            "SPS: 1563\n",
            "global_step=26136, episodic_return=-106.08740234375\n",
            "global_step=26376, episodic_return=-250.77198791503906\n",
            "global_step=26388, episodic_return=-265.2864990234375\n",
            "global_step=26392, episodic_return=-191.8362274169922\n",
            "global_step=26536, episodic_return=-100.27461242675781\n",
            "global_step=26624, episodic_return=-115.15790557861328\n",
            "SPS: 1553\n",
            "global_step=26724, episodic_return=-297.94512939453125\n",
            "global_step=26832, episodic_return=-365.55218505859375\n",
            "global_step=27048, episodic_return=-289.58111572265625\n",
            "global_step=27076, episodic_return=-45.06953048706055\n",
            "global_step=27080, episodic_return=-149.73985290527344\n",
            "SPS: 1547\n",
            "global_step=27212, episodic_return=-201.20140075683594\n",
            "global_step=27364, episodic_return=41.77415466308594\n",
            "global_step=27480, episodic_return=-117.1500244140625\n",
            "global_step=27504, episodic_return=-86.40068817138672\n",
            "global_step=27564, episodic_return=-165.3583984375\n",
            "SPS: 1537\n",
            "global_step=27820, episodic_return=-120.31542205810547\n",
            "global_step=27840, episodic_return=-189.4254150390625\n",
            "global_step=27864, episodic_return=-195.8362579345703\n",
            "global_step=28064, episodic_return=-150.07839965820312\n",
            "SPS: 1524\n",
            "global_step=28196, episodic_return=-53.22442626953125\n",
            "global_step=28224, episodic_return=-119.32881164550781\n",
            "global_step=28228, episodic_return=-156.9801025390625\n",
            "global_step=28424, episodic_return=-156.2198486328125\n",
            "global_step=28604, episodic_return=-144.2257843017578\n",
            "global_step=28608, episodic_return=-124.34589385986328\n",
            "global_step=28612, episodic_return=-142.24453735351562\n",
            "SPS: 1513\n",
            "global_step=28884, episodic_return=-103.81537628173828\n",
            "global_step=28992, episodic_return=-124.03507995605469\n",
            "global_step=29012, episodic_return=-149.39622497558594\n",
            "global_step=29032, episodic_return=-64.78958129882812\n",
            "SPS: 1513\n",
            "global_step=29288, episodic_return=-168.35855102539062\n",
            "global_step=29324, episodic_return=-64.54513549804688\n",
            "global_step=29444, episodic_return=-125.26334381103516\n",
            "global_step=29492, episodic_return=-239.14768981933594\n",
            "global_step=29548, episodic_return=-85.46467590332031\n",
            "SPS: 1512\n",
            "global_step=29704, episodic_return=-127.57342529296875\n",
            "global_step=29820, episodic_return=-77.22614288330078\n",
            "global_step=29908, episodic_return=-161.35191345214844\n",
            "global_step=30040, episodic_return=-116.19677734375\n",
            "global_step=30116, episodic_return=-124.01092529296875\n",
            "global_step=30152, episodic_return=-118.7132568359375\n",
            "SPS: 1513\n",
            "global_step=30340, episodic_return=-130.0205078125\n",
            "global_step=30504, episodic_return=-93.8970718383789\n",
            "global_step=30520, episodic_return=-270.3200378417969\n",
            "global_step=30528, episodic_return=-180.99339294433594\n",
            "SPS: 1516\n",
            "global_step=30760, episodic_return=-139.2047119140625\n",
            "global_step=30860, episodic_return=-145.25318908691406\n",
            "global_step=30952, episodic_return=-151.14280700683594\n",
            "global_step=31104, episodic_return=-136.12338256835938\n",
            "global_step=31116, episodic_return=-78.06587982177734\n",
            "SPS: 1519\n",
            "global_step=31356, episodic_return=-238.75279235839844\n",
            "global_step=31376, episodic_return=-129.22743225097656\n",
            "global_step=31456, episodic_return=-138.88699340820312\n",
            "global_step=31504, episodic_return=-133.44166564941406\n",
            "global_step=31700, episodic_return=-208.2329864501953\n",
            "global_step=31736, episodic_return=-92.84803771972656\n",
            "SPS: 1520\n",
            "global_step=31804, episodic_return=-343.77197265625\n",
            "global_step=31852, episodic_return=-99.50188446044922\n",
            "global_step=31968, episodic_return=-178.32676696777344\n",
            "global_step=32172, episodic_return=-125.72128295898438\n",
            "global_step=32200, episodic_return=-144.07070922851562\n",
            "SPS: 1523\n",
            "global_step=32376, episodic_return=-106.24250793457031\n",
            "global_step=32576, episodic_return=-93.25450897216797\n",
            "global_step=32672, episodic_return=-222.57666015625\n",
            "global_step=32752, episodic_return=-131.94802856445312\n",
            "SPS: 1523\n",
            "global_step=32872, episodic_return=-301.7375793457031\n",
            "global_step=33220, episodic_return=-126.78744506835938\n",
            "SPS: 1520\n",
            "global_step=33292, episodic_return=-176.31602478027344\n",
            "global_step=33316, episodic_return=-156.65733337402344\n",
            "global_step=33616, episodic_return=-136.56126403808594\n",
            "global_step=33792, episodic_return=-63.156280517578125\n",
            "SPS: 1515\n",
            "global_step=33984, episodic_return=-445.2724914550781\n",
            "global_step=34228, episodic_return=-79.34394836425781\n",
            "global_step=34260, episodic_return=-165.25363159179688\n",
            "SPS: 1506\n",
            "global_step=34344, episodic_return=-66.83084869384766\n",
            "global_step=34664, episodic_return=-113.16896057128906\n",
            "global_step=34696, episodic_return=-177.2813720703125\n",
            "global_step=34800, episodic_return=-132.23907470703125\n",
            "SPS: 1498\n",
            "global_step=35084, episodic_return=-59.56502914428711\n",
            "global_step=35156, episodic_return=-143.65896606445312\n",
            "global_step=35204, episodic_return=-296.95849609375\n",
            "SPS: 1487\n",
            "global_step=35384, episodic_return=-117.09642028808594\n",
            "global_step=35468, episodic_return=-66.40278625488281\n",
            "global_step=35596, episodic_return=-231.34390258789062\n",
            "global_step=35772, episodic_return=-11.678947448730469\n",
            "SPS: 1475\n",
            "global_step=35852, episodic_return=48.77421951293945\n",
            "global_step=35888, episodic_return=-44.96394348144531\n",
            "global_step=35976, episodic_return=-111.61583709716797\n",
            "global_step=36072, episodic_return=35.11668395996094\n",
            "global_step=36144, episodic_return=-180.29559326171875\n",
            "global_step=36280, episodic_return=-180.9488525390625\n",
            "global_step=36328, episodic_return=-85.77473449707031\n",
            "SPS: 1477\n",
            "global_step=36404, episodic_return=-87.79993438720703\n",
            "global_step=36580, episodic_return=-338.07489013671875\n",
            "global_step=36680, episodic_return=-210.8353729248047\n",
            "global_step=36724, episodic_return=-200.85574340820312\n",
            "SPS: 1478\n",
            "global_step=36992, episodic_return=-128.03274536132812\n",
            "global_step=37036, episodic_return=-329.71527099609375\n",
            "global_step=37040, episodic_return=-137.60580444335938\n",
            "global_step=37172, episodic_return=-154.1875457763672\n",
            "SPS: 1481\n",
            "global_step=37404, episodic_return=20.378883361816406\n",
            "global_step=37460, episodic_return=-97.57150268554688\n",
            "global_step=37480, episodic_return=-135.3294219970703\n",
            "global_step=37488, episodic_return=-131.5033416748047\n",
            "global_step=37772, episodic_return=-98.02377319335938\n",
            "global_step=37820, episodic_return=-377.18798828125\n",
            "global_step=37832, episodic_return=-139.55844116210938\n",
            "global_step=37872, episodic_return=-118.32197570800781\n",
            "SPS: 1483\n",
            "global_step=38112, episodic_return=-117.39720153808594\n",
            "global_step=38156, episodic_return=-116.66503143310547\n",
            "global_step=38248, episodic_return=-113.9937515258789\n",
            "global_step=38276, episodic_return=-208.84368896484375\n",
            "SPS: 1486\n",
            "global_step=38412, episodic_return=-80.1736831665039\n",
            "global_step=38468, episodic_return=-212.7369384765625\n",
            "global_step=38516, episodic_return=-83.05030059814453\n",
            "global_step=38656, episodic_return=-132.80734252929688\n",
            "global_step=38856, episodic_return=-195.18484497070312\n",
            "global_step=38904, episodic_return=-113.96034240722656\n",
            "SPS: 1487\n",
            "global_step=38992, episodic_return=-144.57154846191406\n",
            "global_step=39016, episodic_return=-117.10694122314453\n",
            "global_step=39220, episodic_return=-251.9634246826172\n",
            "global_step=39376, episodic_return=-158.07412719726562\n",
            "SPS: 1490\n",
            "global_step=39448, episodic_return=-169.1331024169922\n",
            "global_step=39460, episodic_return=-62.215087890625\n",
            "global_step=39580, episodic_return=-396.2180480957031\n",
            "global_step=39748, episodic_return=-194.65054321289062\n",
            "SPS: 1492\n",
            "global_step=40016, episodic_return=-93.33353424072266\n",
            "global_step=40032, episodic_return=-68.7939224243164\n",
            "global_step=40144, episodic_return=-82.85478210449219\n",
            "global_step=40152, episodic_return=-247.6892852783203\n",
            "global_step=40312, episodic_return=-71.67591857910156\n",
            "SPS: 1493\n",
            "global_step=40456, episodic_return=-199.29254150390625\n",
            "global_step=40532, episodic_return=-66.31149291992188\n",
            "global_step=40632, episodic_return=-191.85394287109375\n",
            "global_step=40792, episodic_return=-212.02105712890625\n",
            "global_step=40852, episodic_return=-236.2054443359375\n",
            "SPS: 1494\n",
            "global_step=40988, episodic_return=-247.43951416015625\n",
            "global_step=41044, episodic_return=-131.5976104736328\n",
            "global_step=41096, episodic_return=-87.25038146972656\n",
            "global_step=41220, episodic_return=-270.9971008300781\n",
            "global_step=41344, episodic_return=-100.78343200683594\n",
            "global_step=41400, episodic_return=-89.07221221923828\n",
            "SPS: 1495\n",
            "global_step=41488, episodic_return=-18.02374267578125\n",
            "global_step=41492, episodic_return=-195.0091552734375\n",
            "global_step=41824, episodic_return=-167.88360595703125\n",
            "global_step=41844, episodic_return=-156.0273895263672\n",
            "global_step=41872, episodic_return=-81.12506103515625\n",
            "global_step=41976, episodic_return=-45.740047454833984\n",
            "SPS: 1496\n",
            "global_step=42152, episodic_return=-15.255882263183594\n",
            "global_step=42208, episodic_return=-252.77395629882812\n",
            "global_step=42256, episodic_return=-126.81515502929688\n",
            "SPS: 1499\n",
            "global_step=42560, episodic_return=-76.88098907470703\n",
            "global_step=42564, episodic_return=-108.88398742675781\n",
            "global_step=42620, episodic_return=-191.134521484375\n",
            "global_step=42648, episodic_return=-107.85771179199219\n",
            "global_step=42832, episodic_return=-95.30581665039062\n",
            "global_step=42932, episodic_return=-119.9916763305664\n",
            "SPS: 1500\n",
            "global_step=43040, episodic_return=-192.79885864257812\n",
            "global_step=43104, episodic_return=-291.413330078125\n",
            "global_step=43128, episodic_return=-93.4377212524414\n",
            "global_step=43364, episodic_return=-149.19129943847656\n",
            "global_step=43412, episodic_return=-127.97985076904297\n",
            "global_step=43432, episodic_return=-203.47557067871094\n",
            "global_step=43480, episodic_return=-313.2586669921875\n",
            "SPS: 1502\n",
            "global_step=43684, episodic_return=-86.51614379882812\n",
            "global_step=43696, episodic_return=-97.86739349365234\n",
            "global_step=43912, episodic_return=-139.8181610107422\n",
            "global_step=43984, episodic_return=-111.75190734863281\n",
            "global_step=44004, episodic_return=-121.09490966796875\n",
            "global_step=44012, episodic_return=-82.46581268310547\n",
            "SPS: 1496\n",
            "global_step=44196, episodic_return=-91.96734619140625\n",
            "global_step=44300, episodic_return=-127.36782836914062\n",
            "global_step=44336, episodic_return=-268.5804138183594\n",
            "global_step=44388, episodic_return=-253.4544219970703\n",
            "global_step=44528, episodic_return=-105.02940368652344\n",
            "SPS: 1490\n",
            "global_step=44676, episodic_return=-76.06233978271484\n",
            "global_step=44832, episodic_return=-138.931640625\n",
            "global_step=45000, episodic_return=-45.54127502441406\n",
            "SPS: 1485\n",
            "global_step=45132, episodic_return=-261.5950927734375\n",
            "global_step=45176, episodic_return=-113.9230728149414\n",
            "global_step=45360, episodic_return=-111.56327056884766\n",
            "global_step=45384, episodic_return=-244.324462890625\n",
            "global_step=45432, episodic_return=-105.12093353271484\n",
            "global_step=45548, episodic_return=-111.90076446533203\n",
            "SPS: 1480\n",
            "global_step=45620, episodic_return=-61.408119201660156\n",
            "global_step=45684, episodic_return=-92.46356964111328\n",
            "global_step=45812, episodic_return=-133.10653686523438\n",
            "global_step=45956, episodic_return=-182.80894470214844\n",
            "global_step=46004, episodic_return=-321.5694274902344\n",
            "global_step=46064, episodic_return=-65.53173828125\n",
            "SPS: 1476\n",
            "global_step=46128, episodic_return=-312.934326171875\n",
            "global_step=46324, episodic_return=-271.93170166015625\n",
            "global_step=46380, episodic_return=-73.698486328125\n",
            "global_step=46412, episodic_return=-161.97686767578125\n",
            "global_step=46492, episodic_return=-154.05886840820312\n",
            "SPS: 1472\n",
            "global_step=46656, episodic_return=-127.23515319824219\n",
            "global_step=46784, episodic_return=-493.7100830078125\n",
            "global_step=46832, episodic_return=-69.17787170410156\n",
            "global_step=46884, episodic_return=-186.85028076171875\n",
            "global_step=47096, episodic_return=-128.61798095703125\n",
            "SPS: 1474\n",
            "global_step=47124, episodic_return=-79.83137512207031\n",
            "global_step=47292, episodic_return=-158.05377197265625\n",
            "global_step=47300, episodic_return=-137.93679809570312\n",
            "global_step=47536, episodic_return=-154.5523681640625\n",
            "global_step=47548, episodic_return=-333.81170654296875\n",
            "global_step=47592, episodic_return=-190.61810302734375\n",
            "SPS: 1476\n",
            "global_step=47804, episodic_return=-194.59628295898438\n",
            "global_step=47812, episodic_return=-55.104835510253906\n",
            "global_step=48008, episodic_return=-165.18289184570312\n",
            "global_step=48048, episodic_return=-339.16455078125\n",
            "SPS: 1478\n",
            "global_step=48256, episodic_return=-229.98388671875\n",
            "global_step=48332, episodic_return=-214.79042053222656\n",
            "global_step=48424, episodic_return=-147.063232421875\n",
            "global_step=48480, episodic_return=-104.68831634521484\n",
            "global_step=48572, episodic_return=-95.0121841430664\n",
            "SPS: 1480\n",
            "global_step=48876, episodic_return=-79.15077209472656\n",
            "global_step=48908, episodic_return=-214.78067016601562\n",
            "global_step=48920, episodic_return=-159.86366271972656\n",
            "global_step=48980, episodic_return=-138.83509826660156\n",
            "SPS: 1482\n",
            "global_step=49228, episodic_return=-99.02767944335938\n",
            "global_step=49260, episodic_return=-248.69775390625\n",
            "global_step=49292, episodic_return=-86.11695861816406\n",
            "global_step=49400, episodic_return=-87.2458724975586\n",
            "global_step=49620, episodic_return=-68.14114379882812\n",
            "global_step=49664, episodic_return=-77.08226776123047\n",
            "SPS: 1483\n",
            "\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to 1min.\n",
            "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "\u001b[1;34m[swscaler @ 0x5a9a4c0] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[0m\u001b[38;5;4m‚Ñπ Pushing repo ramsi-k/LunarLander-v2-fromscratch to the Hugging Face\n",
            "Hub\u001b[0m\n",
            "\n",
            "events.out.tfevents.1707298646.0afa5d2aa1c9.4736.0:   0% 0.00/111k [00:00<?, ?B/s]\n",
            "\n",
            "events.out.tfevents.1707298646.0afa5d2aa1c9.4736.0:  15% 16.4k/111k [00:00<00:00, 127kB/s]\n",
            "model.pt: 100% 42.9k/42.9k [00:00<00:00, 87.3kB/s]\n",
            "events.out.tfevents.1707298646.0afa5d2aa1c9.4736.0: 100% 111k/111k [00:00<00:00, 150kB/s] \n",
            "\n",
            "\n",
            "Upload 2 LFS files: 100% 2/2 [00:01<00:00,  1.67it/s]\n",
            "\u001b[38;5;4m‚Ñπ Your model is pushed to the Hub. You can view your model here:\n",
            "https://huggingface.co/ramsi-k/LunarLander-v2-fromscratch/tree/main/\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ppo.py --env-id=\"LunarLander-v2\" --repo-id=\"ramsi-k/LunarLander-v2-fromscratch-tune\" --total-timesteps=50000 --num-envs=64 --num-steps=32 --learning-rate=0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp3VzA-m6B7X",
        "outputId": "3302064b-2432-4804-b552-d450728c5b0c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2024-02-07 09:56:24.950449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-07 09:56:24.950519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-07 09:56:24.951997: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-07 09:56:26.310554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "SPS: 3226\n",
            "global_step=3648, episodic_return=-3.0059967041015625\n",
            "global_step=3968, episodic_return=-73.90293884277344\n",
            "global_step=4032, episodic_return=-84.79701232910156\n",
            "SPS: 2776\n",
            "global_step=4160, episodic_return=-92.0920181274414\n",
            "global_step=4288, episodic_return=-97.3822021484375\n",
            "global_step=4480, episodic_return=-67.41322326660156\n",
            "global_step=4544, episodic_return=-59.94477844238281\n",
            "global_step=4608, episodic_return=-150.1641845703125\n",
            "global_step=4800, episodic_return=-105.05501556396484\n",
            "global_step=4992, episodic_return=-48.26541519165039\n",
            "global_step=5056, episodic_return=-78.16085815429688\n",
            "global_step=5120, episodic_return=-96.61514282226562\n",
            "global_step=5312, episodic_return=-278.20245361328125\n",
            "global_step=5376, episodic_return=-414.50384521484375\n",
            "global_step=5440, episodic_return=-108.15869903564453\n",
            "global_step=5504, episodic_return=-111.67980194091797\n",
            "global_step=5696, episodic_return=-502.8327941894531\n",
            "global_step=5888, episodic_return=-169.6442413330078\n",
            "global_step=5952, episodic_return=-308.3856201171875\n",
            "global_step=6080, episodic_return=-77.42326354980469\n",
            "global_step=6144, episodic_return=-113.58232116699219\n",
            "SPS: 2925\n",
            "global_step=6208, episodic_return=-192.38229370117188\n",
            "global_step=6272, episodic_return=-43.206356048583984\n",
            "global_step=6336, episodic_return=-213.8802490234375\n",
            "global_step=6464, episodic_return=-8.60589599609375\n",
            "global_step=6656, episodic_return=-215.00672912597656\n",
            "global_step=6720, episodic_return=-174.9137420654297\n",
            "global_step=6784, episodic_return=-116.29439544677734\n",
            "global_step=6848, episodic_return=-134.5738067626953\n",
            "global_step=6912, episodic_return=-112.68910217285156\n",
            "global_step=7040, episodic_return=-186.86517333984375\n",
            "global_step=7104, episodic_return=-95.58307647705078\n",
            "global_step=7296, episodic_return=-95.45710754394531\n",
            "global_step=7616, episodic_return=-373.3594665527344\n",
            "global_step=7680, episodic_return=-332.5755920410156\n",
            "global_step=7872, episodic_return=-91.77696990966797\n",
            "global_step=8000, episodic_return=-198.11065673828125\n",
            "global_step=8064, episodic_return=-343.9256286621094\n",
            "SPS: 3074\n",
            "global_step=8768, episodic_return=-235.2659454345703\n",
            "global_step=8832, episodic_return=-220.51950073242188\n",
            "global_step=9664, episodic_return=-282.97601318359375\n",
            "global_step=9856, episodic_return=-69.45768737792969\n",
            "global_step=9920, episodic_return=-195.08074951171875\n",
            "global_step=10112, episodic_return=-69.00605010986328\n",
            "global_step=10176, episodic_return=-145.45916748046875\n",
            "SPS: 3182\n",
            "global_step=10304, episodic_return=-81.47582244873047\n",
            "global_step=10432, episodic_return=-89.52189636230469\n",
            "global_step=10752, episodic_return=-73.85858154296875\n",
            "global_step=11072, episodic_return=-67.12086486816406\n",
            "global_step=11264, episodic_return=-97.61927795410156\n",
            "global_step=11328, episodic_return=-101.5394287109375\n",
            "global_step=11392, episodic_return=-190.639892578125\n",
            "global_step=11456, episodic_return=-88.28326416015625\n",
            "global_step=11648, episodic_return=-181.82925415039062\n",
            "global_step=11712, episodic_return=-97.22000122070312\n",
            "global_step=11904, episodic_return=-17.051300048828125\n",
            "global_step=11968, episodic_return=-115.92454528808594\n",
            "global_step=12032, episodic_return=-80.98037719726562\n",
            "global_step=12160, episodic_return=-74.00830078125\n",
            "global_step=12224, episodic_return=-142.16494750976562\n",
            "global_step=12288, episodic_return=-78.39527130126953\n",
            "SPS: 3199\n",
            "global_step=12480, episodic_return=-94.22994995117188\n",
            "global_step=12544, episodic_return=-92.434326171875\n",
            "global_step=12736, episodic_return=-227.4119415283203\n",
            "global_step=12800, episodic_return=-298.6533203125\n",
            "global_step=12928, episodic_return=-153.6353759765625\n",
            "global_step=13312, episodic_return=-155.97018432617188\n",
            "global_step=13376, episodic_return=-166.13885498046875\n",
            "global_step=13504, episodic_return=-107.87599182128906\n",
            "global_step=13568, episodic_return=-133.54298400878906\n",
            "global_step=13632, episodic_return=-83.22364807128906\n",
            "global_step=13696, episodic_return=-186.31103515625\n",
            "global_step=13824, episodic_return=-281.9292907714844\n",
            "global_step=13888, episodic_return=-207.08456420898438\n",
            "SPS: 3223\n",
            "global_step=14400, episodic_return=-173.23764038085938\n",
            "global_step=14464, episodic_return=-83.78620910644531\n",
            "global_step=14720, episodic_return=-66.13517761230469\n",
            "global_step=14848, episodic_return=-54.83160400390625\n",
            "global_step=14912, episodic_return=-352.3639221191406\n",
            "global_step=14976, episodic_return=-100.44619750976562\n",
            "global_step=15296, episodic_return=-48.33826446533203\n",
            "global_step=15424, episodic_return=-118.59237670898438\n",
            "global_step=15552, episodic_return=-90.88787078857422\n",
            "global_step=15616, episodic_return=-110.50938415527344\n",
            "global_step=15808, episodic_return=-108.46472930908203\n",
            "global_step=15936, episodic_return=-277.60247802734375\n",
            "global_step=16000, episodic_return=-208.08998107910156\n",
            "global_step=16064, episodic_return=-38.602806091308594\n",
            "global_step=16384, episodic_return=-57.17891311645508\n",
            "SPS: 3238\n",
            "global_step=16512, episodic_return=-160.12820434570312\n",
            "global_step=16576, episodic_return=-55.75800704956055\n",
            "global_step=16640, episodic_return=-194.0985107421875\n",
            "global_step=16832, episodic_return=-86.37236022949219\n",
            "global_step=16960, episodic_return=-73.29995727539062\n",
            "global_step=17024, episodic_return=-124.22065734863281\n",
            "global_step=17088, episodic_return=-303.72088623046875\n",
            "global_step=17216, episodic_return=-23.748641967773438\n",
            "global_step=17344, episodic_return=-159.6688690185547\n",
            "global_step=17792, episodic_return=-342.9513244628906\n",
            "global_step=17856, episodic_return=-53.272308349609375\n",
            "global_step=17984, episodic_return=-127.59562683105469\n",
            "global_step=18304, episodic_return=-91.90280151367188\n",
            "SPS: 3249\n",
            "global_step=18624, episodic_return=-451.6515197753906\n",
            "global_step=18688, episodic_return=-58.115787506103516\n",
            "global_step=18816, episodic_return=-60.72557830810547\n",
            "global_step=19008, episodic_return=-53.57166290283203\n",
            "global_step=19136, episodic_return=-61.77995300292969\n",
            "global_step=19264, episodic_return=-188.64013671875\n",
            "global_step=19456, episodic_return=-74.27422332763672\n",
            "global_step=19520, episodic_return=-66.99896240234375\n",
            "global_step=19776, episodic_return=-159.44406127929688\n",
            "global_step=19840, episodic_return=-115.25154113769531\n",
            "global_step=19968, episodic_return=-163.01683044433594\n",
            "global_step=20352, episodic_return=-95.51761627197266\n",
            "global_step=20480, episodic_return=-119.87774658203125\n",
            "SPS: 3248\n",
            "global_step=20608, episodic_return=-48.103187561035156\n",
            "global_step=20672, episodic_return=-79.86845397949219\n",
            "global_step=21120, episodic_return=-48.974056243896484\n",
            "global_step=21312, episodic_return=-161.58206176757812\n",
            "global_step=21376, episodic_return=-106.71467590332031\n",
            "global_step=21504, episodic_return=-19.471473693847656\n",
            "global_step=22272, episodic_return=-114.8183364868164\n",
            "SPS: 3240\n",
            "global_step=22592, episodic_return=-264.6502685546875\n",
            "global_step=22656, episodic_return=-135.33792114257812\n",
            "global_step=22912, episodic_return=-268.23028564453125\n",
            "global_step=23104, episodic_return=-384.1562805175781\n",
            "global_step=23360, episodic_return=-93.73602294921875\n",
            "global_step=23424, episodic_return=-244.79258728027344\n",
            "global_step=23616, episodic_return=-239.57342529296875\n",
            "global_step=23680, episodic_return=-182.27597045898438\n",
            "global_step=23744, episodic_return=-239.21859741210938\n",
            "global_step=24000, episodic_return=-80.79069519042969\n",
            "global_step=24128, episodic_return=-55.535457611083984\n",
            "global_step=24192, episodic_return=-49.49753189086914\n",
            "global_step=24256, episodic_return=-166.12588500976562\n",
            "global_step=24320, episodic_return=-286.3423767089844\n",
            "global_step=24384, episodic_return=-144.57305908203125\n",
            "global_step=24512, episodic_return=-61.94633483886719\n",
            "global_step=24576, episodic_return=-370.8163757324219\n",
            "SPS: 3214\n",
            "global_step=24768, episodic_return=-243.63876342773438\n",
            "global_step=25088, episodic_return=-57.17208480834961\n",
            "global_step=25152, episodic_return=-33.59617614746094\n",
            "global_step=25344, episodic_return=-40.47736358642578\n",
            "global_step=25472, episodic_return=-112.90885162353516\n",
            "global_step=25600, episodic_return=-12.264556884765625\n",
            "global_step=25664, episodic_return=-40.80091094970703\n",
            "global_step=25728, episodic_return=-308.3173828125\n",
            "global_step=25856, episodic_return=-84.2718276977539\n",
            "global_step=25920, episodic_return=-83.70716857910156\n",
            "global_step=25984, episodic_return=-270.47442626953125\n",
            "global_step=26048, episodic_return=0.8863372802734375\n",
            "global_step=26176, episodic_return=-310.4308166503906\n",
            "global_step=26240, episodic_return=-69.08845520019531\n",
            "global_step=26304, episodic_return=-50.61705017089844\n",
            "global_step=26368, episodic_return=-85.6939926147461\n",
            "global_step=26560, episodic_return=-252.88677978515625\n",
            "SPS: 3188\n",
            "global_step=26752, episodic_return=-158.6217041015625\n",
            "global_step=26880, episodic_return=-138.5716552734375\n",
            "global_step=26944, episodic_return=-373.98968505859375\n",
            "global_step=27072, episodic_return=-384.1535339355469\n",
            "global_step=27584, episodic_return=-96.07237243652344\n",
            "global_step=27968, episodic_return=-131.95570373535156\n",
            "global_step=28160, episodic_return=-155.46080017089844\n",
            "global_step=28352, episodic_return=-5.797737121582031\n",
            "global_step=28608, episodic_return=-154.20230102539062\n",
            "global_step=28672, episodic_return=-315.93890380859375\n",
            "SPS: 3179\n",
            "global_step=28736, episodic_return=-123.59207916259766\n",
            "global_step=28800, episodic_return=-180.48373413085938\n",
            "global_step=28864, episodic_return=-27.26758575439453\n",
            "global_step=28928, episodic_return=-225.5230255126953\n",
            "global_step=29120, episodic_return=-21.235267639160156\n",
            "global_step=29824, episodic_return=-53.485328674316406\n",
            "global_step=29952, episodic_return=-87.72969055175781\n",
            "global_step=30336, episodic_return=-258.6904296875\n",
            "global_step=30400, episodic_return=-58.86349868774414\n",
            "global_step=30464, episodic_return=-52.68032455444336\n",
            "global_step=30528, episodic_return=-51.643680572509766\n",
            "global_step=30656, episodic_return=-73.70003509521484\n",
            "SPS: 3169\n",
            "global_step=31104, episodic_return=-62.71123123168945\n",
            "global_step=31296, episodic_return=-116.25727844238281\n",
            "global_step=31360, episodic_return=-67.27926635742188\n",
            "global_step=32000, episodic_return=-121.62612915039062\n",
            "global_step=32192, episodic_return=-97.98942565917969\n",
            "global_step=32256, episodic_return=-256.8798522949219\n",
            "global_step=32448, episodic_return=-201.41268920898438\n",
            "global_step=32512, episodic_return=-71.71846008300781\n",
            "SPS: 3160\n",
            "global_step=32832, episodic_return=-75.30799865722656\n",
            "global_step=32896, episodic_return=-211.56808471679688\n",
            "global_step=33024, episodic_return=-98.00753021240234\n",
            "global_step=33216, episodic_return=-193.42633056640625\n",
            "global_step=33280, episodic_return=-92.39837646484375\n",
            "global_step=33344, episodic_return=-11.3553466796875\n",
            "global_step=33408, episodic_return=-85.19940948486328\n",
            "global_step=33600, episodic_return=-190.85110473632812\n",
            "global_step=33920, episodic_return=-22.446975708007812\n",
            "global_step=34304, episodic_return=-57.526695251464844\n",
            "global_step=34368, episodic_return=-274.6129150390625\n",
            "global_step=34624, episodic_return=-213.09597778320312\n",
            "global_step=34752, episodic_return=-9.916610717773438\n",
            "SPS: 3145\n",
            "global_step=34880, episodic_return=-74.65666198730469\n",
            "global_step=35072, episodic_return=-295.0057067871094\n",
            "global_step=35328, episodic_return=-116.7340087890625\n",
            "global_step=35456, episodic_return=-57.800559997558594\n",
            "global_step=35520, episodic_return=12.084053039550781\n",
            "global_step=35776, episodic_return=-61.21665954589844\n",
            "global_step=35840, episodic_return=-172.39967346191406\n",
            "global_step=35968, episodic_return=-105.24292755126953\n",
            "global_step=36032, episodic_return=-7.978584289550781\n",
            "global_step=36288, episodic_return=-65.20365142822266\n",
            "global_step=36352, episodic_return=-237.94363403320312\n",
            "global_step=36608, episodic_return=-270.7864990234375\n",
            "global_step=36864, episodic_return=-342.61541748046875\n",
            "SPS: 3095\n",
            "global_step=36992, episodic_return=-135.70458984375\n",
            "global_step=37184, episodic_return=-72.8968505859375\n",
            "global_step=37312, episodic_return=-194.88052368164062\n",
            "global_step=37376, episodic_return=-109.58434295654297\n",
            "global_step=37760, episodic_return=-221.20147705078125\n",
            "global_step=38080, episodic_return=-113.35197448730469\n",
            "global_step=38336, episodic_return=16.28876495361328\n",
            "global_step=38400, episodic_return=-117.952392578125\n",
            "global_step=38720, episodic_return=-123.67012786865234\n",
            "global_step=38848, episodic_return=4.847969055175781\n",
            "SPS: 3005\n",
            "global_step=38976, episodic_return=-106.27128601074219\n",
            "global_step=39040, episodic_return=-73.3204345703125\n",
            "global_step=39232, episodic_return=-236.0146942138672\n",
            "global_step=39424, episodic_return=-257.08349609375\n",
            "global_step=39616, episodic_return=-96.74009704589844\n",
            "global_step=39680, episodic_return=20.32331085205078\n",
            "global_step=39744, episodic_return=-124.4800796508789\n",
            "global_step=39936, episodic_return=-199.85812377929688\n",
            "global_step=40064, episodic_return=-239.7292938232422\n",
            "global_step=40576, episodic_return=-52.44940948486328\n",
            "SPS: 2914\n",
            "global_step=41152, episodic_return=-322.491943359375\n",
            "global_step=41472, episodic_return=-145.84776306152344\n",
            "global_step=41536, episodic_return=-211.31024169921875\n",
            "global_step=41600, episodic_return=-25.953765869140625\n",
            "global_step=41728, episodic_return=-12.295562744140625\n",
            "global_step=41856, episodic_return=-96.80085754394531\n",
            "global_step=41920, episodic_return=-60.25092697143555\n",
            "global_step=42112, episodic_return=-36.83353042602539\n",
            "global_step=42240, episodic_return=-33.244834899902344\n",
            "global_step=42496, episodic_return=-230.41497802734375\n",
            "global_step=42624, episodic_return=-189.49526977539062\n",
            "global_step=42688, episodic_return=32.90931701660156\n",
            "global_step=42880, episodic_return=-262.0010681152344\n",
            "SPS: 2907\n",
            "global_step=43072, episodic_return=-155.65390014648438\n",
            "global_step=43456, episodic_return=-436.2091369628906\n",
            "global_step=43520, episodic_return=-123.12815856933594\n",
            "global_step=44480, episodic_return=-154.31744384765625\n",
            "global_step=44736, episodic_return=-161.0011444091797\n",
            "global_step=44800, episodic_return=-91.01661682128906\n",
            "global_step=44864, episodic_return=-140.59400939941406\n",
            "global_step=44992, episodic_return=-64.44727325439453\n",
            "SPS: 2904\n",
            "global_step=45184, episodic_return=-124.87218475341797\n",
            "global_step=45440, episodic_return=6.269691467285156\n",
            "global_step=45568, episodic_return=-59.48179626464844\n",
            "global_step=45760, episodic_return=-163.5729522705078\n",
            "global_step=45952, episodic_return=-130.22372436523438\n",
            "global_step=46272, episodic_return=-231.60525512695312\n",
            "global_step=46528, episodic_return=-382.85693359375\n",
            "global_step=46784, episodic_return=-18.376174926757812\n",
            "SPS: 2901\n",
            "global_step=47360, episodic_return=-240.6395263671875\n",
            "global_step=47488, episodic_return=-386.3525695800781\n",
            "global_step=47552, episodic_return=-209.22406005859375\n",
            "global_step=47616, episodic_return=-160.83541870117188\n",
            "global_step=47680, episodic_return=-276.2179260253906\n",
            "global_step=47936, episodic_return=-259.4141845703125\n",
            "global_step=48000, episodic_return=-177.28607177734375\n",
            "global_step=48064, episodic_return=-100.85676574707031\n",
            "global_step=48512, episodic_return=-57.62394714355469\n",
            "global_step=48832, episodic_return=-74.36479187011719\n",
            "global_step=48896, episodic_return=-305.828369140625\n",
            "global_step=48960, episodic_return=-114.76628875732422\n",
            "global_step=49088, episodic_return=-110.2434310913086\n",
            "global_step=49152, episodic_return=-34.17808532714844\n",
            "SPS: 2895\n",
            "\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to 1min.\n",
            "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "\u001b[1;34m[swscaler @ 0x60f84c0] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[0m\u001b[38;5;4m‚Ñπ Pushing repo ramsi-k/LunarLander-v2-fromscratch-tune to the Hugging\n",
            "Face Hub\u001b[0m\n",
            "Upload 2 LFS files:   0% 0/2 [00:00<?, ?it/s]\n",
            "events.out.tfevents.1707299788.0afa5d2aa1c9.9401.0:   0% 0.00/47.0k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model.pt:   0% 0.00/42.9k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "events.out.tfevents.1707299788.0afa5d2aa1c9.9401.0:  35% 16.4k/47.0k [00:00<00:00, 137kB/s]\u001b[A\n",
            "\n",
            "model.pt: 100% 42.9k/42.9k [00:00<00:00, 85.9kB/s]\n",
            "events.out.tfevents.1707299788.0afa5d2aa1c9.9401.0: 100% 47.0k/47.0k [00:00<00:00, 75.2kB/s]\n",
            "Upload 2 LFS files: 100% 2/2 [00:00<00:00,  2.06it/s]\n",
            "\u001b[38;5;4m‚Ñπ Your model is pushed to the Hub. You can view your model here:\n",
            "https://huggingface.co/ramsi-k/LunarLander-v2-fromscratch-tune/tree/main/\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVsVJ5AdqLE7"
      },
      "source": [
        "## Some additional challenges üèÜ\n",
        "The best way to learn **is to try things by your own**! Why not trying  another environment?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYdl758GqLXT"
      },
      "source": [
        "See you on Unit 8, part 2 where we going to train agents to play Doom üî•\n",
        "## Keep learning, stay awesome ü§ó"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4e709804cf048b0b088bdbb7fead0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a20d63c4a594dc98a9e7eafb33e4684",
              "IPY_MODEL_75464c1f38904a689a8a5911d3b04aa4",
              "IPY_MODEL_480856c9c36844b98daa9e104a365167",
              "IPY_MODEL_49332511a2be40d1870f043060140f54"
            ],
            "layout": "IPY_MODEL_0fb05dfdefd441c29d5de83e0969a91d"
          }
        },
        "1c880e1666c042efa66f5cd280eb68e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2e6986aad34282a54ed12af5fd3e84",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9d6b83b242354fc4b76d1f3679cc5b7a",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "9121302ae89b4a3e9c96aaace43584ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cdeb17b979d247d8b3c2dff49be30769",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_03af986d99c048ddb691ac28997a6003",
            "value": ""
          }
        },
        "19f1f4ec716e48d0ba90be344bd9901e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_90c49d0396d34086b96649c52225a43a",
            "style": "IPY_MODEL_0d804a48db694573896456faff94a036",
            "value": true
          }
        },
        "04f7eb6115d54030be33b730264233b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_afb08af88dea45039fb8b48643390a49",
            "style": "IPY_MODEL_b7ddf907e5a94f88952f085a7884afe2",
            "tooltip": ""
          }
        },
        "dedbc9335df24866bdf5b665ca28b165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83da2a0e44044e04a7bba948bcecd90c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3be1337be02745e5877d73c9120aafd0",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "0fb05dfdefd441c29d5de83e0969a91d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2d2e6986aad34282a54ed12af5fd3e84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6b83b242354fc4b76d1f3679cc5b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdeb17b979d247d8b3c2dff49be30769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03af986d99c048ddb691ac28997a6003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90c49d0396d34086b96649c52225a43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d804a48db694573896456faff94a036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb08af88dea45039fb8b48643390a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ddf907e5a94f88952f085a7884afe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "83da2a0e44044e04a7bba948bcecd90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be1337be02745e5877d73c9120aafd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1d03a3f67e44c90a47e9c4925b1e472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b813ba9a73e467ead59249938186c2c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b9777fb0b2224a35a2791293d9293dd5",
            "value": "Connecting..."
          }
        },
        "4b813ba9a73e467ead59249938186c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9777fb0b2224a35a2791293d9293dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a20d63c4a594dc98a9e7eafb33e4684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b918083d683485096d27364d85869e1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_93d42b6f467d4546b9d2983e177e71cc",
            "value": "Token is valid (permission: write)."
          }
        },
        "75464c1f38904a689a8a5911d3b04aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9b2d8424c824c39a7a6a1010065ccea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_71bd8b4e48b946d280f5a512c74b1e34",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "480856c9c36844b98daa9e104a365167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e503fc32cfb423581b6c730f76e7e50",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_08342d23ffde4cc0b1d3159814bbb97a",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "49332511a2be40d1870f043060140f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca1abcc3e2dc4ef98d54838e25212f0a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_38eb98b2171449329dd75535e183e399",
            "value": "Login successful"
          }
        },
        "9b918083d683485096d27364d85869e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d42b6f467d4546b9d2983e177e71cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9b2d8424c824c39a7a6a1010065ccea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71bd8b4e48b946d280f5a512c74b1e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e503fc32cfb423581b6c730f76e7e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08342d23ffde4cc0b1d3159814bbb97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca1abcc3e2dc4ef98d54838e25212f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38eb98b2171449329dd75535e183e399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}